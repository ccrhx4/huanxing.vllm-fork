Namespace(backend='vllm', dataset=None, input_len=128, output_len=1024, model='meta-llama/Meta-Llama-3-8B', tokenizer='meta-llama/Meta-Llama-3-8B', quantization=None, tensor_parallel_size=1, n=1, use_beam_search=False, num_prompts=256, seed=0, hf_max_batch_size=None, trust_remote_code=False, max_model_len=None, dtype='bfloat16', gpu_memory_utilization=0.9, enforce_eager=False, kv_cache_dtype='auto', quantization_param_path=None, device='hpu', enable_prefix_caching=False, enable_chunked_prefill=False, max_num_batched_tokens=None, download_dir=None)
INFO 06-19 07:39:21 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='meta-llama/Meta-Llama-3-8B', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=hpu, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=meta-llama/Meta-Llama-3-8B)
INFO 06-19 07:39:21 profiler.py:59] Profiler enabled for: vllm-instance-a09471a60db04383bfcedf3cead5fb7f
WARNING 06-19 07:39:21 utils.py:454] Pin memory is not supported on HPU.
INFO 06-19 07:39:21 selector.py:52] Using HabanaAttention backend.
INFO 06-19 07:39:21 habana_model_runner.py:328] Prompt bucket config (min, step, max_warmup) bs:[1, 32, 64], seq:[128, 128, 1024]
INFO 06-19 07:39:21 habana_model_runner.py:330] Generated 56 prompt buckets: [(1, 128), (1, 256), (1, 384), (1, 512), (1, 640), (1, 768), (1, 896), (1, 1024), (2, 128), (2, 256), (2, 384), (2, 512), (2, 640), (2, 768), (2, 896), (2, 1024), (4, 128), (4, 256), (4, 384), (4, 512), (4, 640), (4, 768), (4, 896), (4, 1024), (8, 128), (8, 256), (8, 384), (8, 512), (8, 640), (8, 768), (8, 896), (8, 1024), (16, 128), (16, 256), (16, 384), (16, 512), (16, 640), (16, 768), (16, 896), (16, 1024), (32, 128), (32, 256), (32, 384), (32, 512), (32, 640), (32, 768), (32, 896), (32, 1024), (64, 128), (64, 256), (64, 384), (64, 512), (64, 640), (64, 768), (64, 896), (64, 1024)]
INFO 06-19 07:39:21 habana_model_runner.py:332] Decode bucket config (min, step, max_warmup) bs:[1, 128, 256], seq:[128, 128, 2048]
INFO 06-19 07:39:21 habana_model_runner.py:334] Generated 144 decode buckets: [(1, 128), (1, 256), (1, 384), (1, 512), (1, 640), (1, 768), (1, 896), (1, 1024), (1, 1152), (1, 1280), (1, 1408), (1, 1536), (1, 1664), (1, 1792), (1, 1920), (1, 2048), (2, 128), (2, 256), (2, 384), (2, 512), (2, 640), (2, 768), (2, 896), (2, 1024), (2, 1152), (2, 1280), (2, 1408), (2, 1536), (2, 1664), (2, 1792), (2, 1920), (2, 2048), (4, 128), (4, 256), (4, 384), (4, 512), (4, 640), (4, 768), (4, 896), (4, 1024), (4, 1152), (4, 1280), (4, 1408), (4, 1536), (4, 1664), (4, 1792), (4, 1920), (4, 2048), (8, 128), (8, 256), (8, 384), (8, 512), (8, 640), (8, 768), (8, 896), (8, 1024), (8, 1152), (8, 1280), (8, 1408), (8, 1536), (8, 1664), (8, 1792), (8, 1920), (8, 2048), (16, 128), (16, 256), (16, 384), (16, 512), (16, 640), (16, 768), (16, 896), (16, 1024), (16, 1152), (16, 1280), (16, 1408), (16, 1536), (16, 1664), (16, 1792), (16, 1920), (16, 2048), (32, 128), (32, 256), (32, 384), (32, 512), (32, 640), (32, 768), (32, 896), (32, 1024), (32, 1152), (32, 1280), (32, 1408), (32, 1536), (32, 1664), (32, 1792), (32, 1920), (32, 2048), (64, 128), (64, 256), (64, 384), (64, 512), (64, 640), (64, 768), (64, 896), (64, 1024), (64, 1152), (64, 1280), (64, 1408), (64, 1536), (64, 1664), (64, 1792), (64, 1920), (64, 2048), (128, 128), (128, 256), (128, 384), (128, 512), (128, 640), (128, 768), (128, 896), (128, 1024), (128, 1152), (128, 1280), (128, 1408), (128, 1536), (128, 1664), (128, 1792), (128, 1920), (128, 2048), (256, 128), (256, 256), (256, 384), (256, 512), (256, 640), (256, 768), (256, 896), (256, 1024), (256, 1152), (256, 1280), (256, 1408), (256, 1536), (256, 1664), (256, 1792), (256, 1920), (256, 2048)]
INFO 06-19 07:39:24 weight_utils.py:199] Using model weights format ['*.safetensors']
INFO 06-19 07:39:27 habana_model_runner.py:284] Pre-loading model weights on hpu:0 took 14.96 GiB of device memory (14.97 GiB/94.62 GiB used) and 35.94 MiB of host memory (7.766 GiB/108.1 GiB used)
INFO 06-19 07:39:27 habana_model_runner.py:289] Wrapping in HPU Graph took 0 B of device memory (14.97 GiB/94.62 GiB used) and -508 KiB of host memory (7.766 GiB/108.1 GiB used)
INFO 06-19 07:39:27 habana_model_runner.py:292] Loading model weights took in total 14.96 GiB of device memory (14.97 GiB/94.62 GiB used) and 35.44 MiB of host memory (7.766 GiB/108.1 GiB used)
INFO 06-19 07:39:27 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:28 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:28 pynccl_utils.py:17] Failed to import NCCL library: NCCL only supports CUDA and ROCm backends.
INFO 06-19 07:39:28 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
INFO 06-19 07:39:32 habana_executor.py:78] # HPU blocks: 2597, # CPU blocks: 256
INFO 06-19 07:39:32 habana_model_runner.py:955] [Warmup][Prompt][1/56] batch_size:64 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 07:39:32 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:32 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:36 habana_model_runner.py:955] [Warmup][Prompt][2/56] batch_size:64 seq_len:896 free_mem:34.58 GiB
INFO 06-19 07:39:36 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:36 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:40 habana_model_runner.py:955] [Warmup][Prompt][3/56] batch_size:64 seq_len:768 free_mem:34.58 GiB
INFO 06-19 07:39:40 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:41 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:44 habana_model_runner.py:955] [Warmup][Prompt][4/56] batch_size:64 seq_len:640 free_mem:34.58 GiB
INFO 06-19 07:39:44 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:44 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:47 habana_model_runner.py:955] [Warmup][Prompt][5/56] batch_size:32 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 07:39:47 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:47 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:50 habana_model_runner.py:955] [Warmup][Prompt][6/56] batch_size:64 seq_len:512 free_mem:34.58 GiB
INFO 06-19 07:39:50 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:50 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:52 habana_model_runner.py:955] [Warmup][Prompt][7/56] batch_size:32 seq_len:896 free_mem:34.58 GiB
INFO 06-19 07:39:52 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:52 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:54 habana_model_runner.py:955] [Warmup][Prompt][8/56] batch_size:32 seq_len:768 free_mem:34.58 GiB
INFO 06-19 07:39:54 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:54 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:56 habana_model_runner.py:955] [Warmup][Prompt][9/56] batch_size:64 seq_len:384 free_mem:34.58 GiB
INFO 06-19 07:39:56 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:56 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:58 habana_model_runner.py:955] [Warmup][Prompt][10/56] batch_size:32 seq_len:640 free_mem:34.58 GiB
INFO 06-19 07:39:58 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:39:58 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:00 habana_model_runner.py:955] [Warmup][Prompt][11/56] batch_size:16 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 07:40:00 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:00 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:01 habana_model_runner.py:955] [Warmup][Prompt][12/56] batch_size:32 seq_len:512 free_mem:34.58 GiB
INFO 06-19 07:40:01 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:01 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:03 habana_model_runner.py:955] [Warmup][Prompt][13/56] batch_size:64 seq_len:256 free_mem:34.58 GiB
INFO 06-19 07:40:03 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:03 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:04 habana_model_runner.py:955] [Warmup][Prompt][14/56] batch_size:16 seq_len:896 free_mem:34.58 GiB
INFO 06-19 07:40:04 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:04 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:05 habana_model_runner.py:955] [Warmup][Prompt][15/56] batch_size:16 seq_len:768 free_mem:34.58 GiB
INFO 06-19 07:40:05 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:05 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:07 habana_model_runner.py:955] [Warmup][Prompt][16/56] batch_size:32 seq_len:384 free_mem:34.58 GiB
INFO 06-19 07:40:07 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:07 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:08 habana_model_runner.py:955] [Warmup][Prompt][17/56] batch_size:16 seq_len:640 free_mem:34.58 GiB
INFO 06-19 07:40:08 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:08 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:09 habana_model_runner.py:955] [Warmup][Prompt][18/56] batch_size:8 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 07:40:09 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:09 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:10 habana_model_runner.py:955] [Warmup][Prompt][19/56] batch_size:16 seq_len:512 free_mem:34.58 GiB
INFO 06-19 07:40:10 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:10 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:11 habana_model_runner.py:955] [Warmup][Prompt][20/56] batch_size:32 seq_len:256 free_mem:34.58 GiB
INFO 06-19 07:40:11 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:11 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:12 habana_model_runner.py:955] [Warmup][Prompt][21/56] batch_size:64 seq_len:128 free_mem:34.58 GiB
INFO 06-19 07:40:12 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:12 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:12 habana_model_runner.py:955] [Warmup][Prompt][22/56] batch_size:8 seq_len:896 free_mem:34.58 GiB
INFO 06-19 07:40:12 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:12 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:13 habana_model_runner.py:955] [Warmup][Prompt][23/56] batch_size:8 seq_len:768 free_mem:34.58 GiB
INFO 06-19 07:40:13 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:13 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:14 habana_model_runner.py:955] [Warmup][Prompt][24/56] batch_size:16 seq_len:384 free_mem:34.58 GiB
INFO 06-19 07:40:14 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:14 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:15 habana_model_runner.py:955] [Warmup][Prompt][25/56] batch_size:8 seq_len:640 free_mem:34.58 GiB
INFO 06-19 07:40:15 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:15 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:16 habana_model_runner.py:955] [Warmup][Prompt][26/56] batch_size:4 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 07:40:16 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:16 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:16 habana_model_runner.py:955] [Warmup][Prompt][27/56] batch_size:8 seq_len:512 free_mem:34.58 GiB
INFO 06-19 07:40:16 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:16 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:17 habana_model_runner.py:955] [Warmup][Prompt][28/56] batch_size:16 seq_len:256 free_mem:34.58 GiB
INFO 06-19 07:40:17 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:17 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:18 habana_model_runner.py:955] [Warmup][Prompt][29/56] batch_size:32 seq_len:128 free_mem:34.58 GiB
INFO 06-19 07:40:18 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:18 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:18 habana_model_runner.py:955] [Warmup][Prompt][30/56] batch_size:4 seq_len:896 free_mem:34.58 GiB
INFO 06-19 07:40:18 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:18 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:19 habana_model_runner.py:955] [Warmup][Prompt][31/56] batch_size:4 seq_len:768 free_mem:34.58 GiB
INFO 06-19 07:40:19 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:19 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:20 habana_model_runner.py:955] [Warmup][Prompt][32/56] batch_size:8 seq_len:384 free_mem:34.58 GiB
INFO 06-19 07:40:20 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:20 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:20 habana_model_runner.py:955] [Warmup][Prompt][33/56] batch_size:4 seq_len:640 free_mem:34.58 GiB
INFO 06-19 07:40:20 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:20 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:21 habana_model_runner.py:955] [Warmup][Prompt][34/56] batch_size:2 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 07:40:21 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:21 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:21 habana_model_runner.py:955] [Warmup][Prompt][35/56] batch_size:4 seq_len:512 free_mem:34.58 GiB
INFO 06-19 07:40:21 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:21 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:22 habana_model_runner.py:955] [Warmup][Prompt][36/56] batch_size:8 seq_len:256 free_mem:34.58 GiB
INFO 06-19 07:40:22 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:22 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:23 habana_model_runner.py:955] [Warmup][Prompt][37/56] batch_size:16 seq_len:128 free_mem:34.58 GiB
INFO 06-19 07:40:23 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:23 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:23 habana_model_runner.py:955] [Warmup][Prompt][38/56] batch_size:2 seq_len:896 free_mem:34.58 GiB
INFO 06-19 07:40:23 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:23 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:24 habana_model_runner.py:955] [Warmup][Prompt][39/56] batch_size:2 seq_len:768 free_mem:34.58 GiB
INFO 06-19 07:40:24 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:24 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:24 habana_model_runner.py:955] [Warmup][Prompt][40/56] batch_size:4 seq_len:384 free_mem:34.58 GiB
INFO 06-19 07:40:24 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:24 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:25 habana_model_runner.py:955] [Warmup][Prompt][41/56] batch_size:2 seq_len:640 free_mem:34.58 GiB
INFO 06-19 07:40:25 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:25 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:25 habana_model_runner.py:955] [Warmup][Prompt][42/56] batch_size:1 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 07:40:25 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:25 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:26 habana_model_runner.py:955] [Warmup][Prompt][43/56] batch_size:2 seq_len:512 free_mem:34.58 GiB
INFO 06-19 07:40:26 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:26 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:26 habana_model_runner.py:955] [Warmup][Prompt][44/56] batch_size:4 seq_len:256 free_mem:34.58 GiB
INFO 06-19 07:40:26 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:26 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:27 habana_model_runner.py:955] [Warmup][Prompt][45/56] batch_size:8 seq_len:128 free_mem:34.58 GiB
INFO 06-19 07:40:27 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:27 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:27 habana_model_runner.py:955] [Warmup][Prompt][46/56] batch_size:1 seq_len:896 free_mem:34.58 GiB
INFO 06-19 07:40:27 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:27 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:28 habana_model_runner.py:955] [Warmup][Prompt][47/56] batch_size:1 seq_len:768 free_mem:34.58 GiB
INFO 06-19 07:40:28 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:28 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:28 habana_model_runner.py:955] [Warmup][Prompt][48/56] batch_size:2 seq_len:384 free_mem:34.58 GiB
INFO 06-19 07:40:28 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:28 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:29 habana_model_runner.py:955] [Warmup][Prompt][49/56] batch_size:1 seq_len:640 free_mem:34.58 GiB
INFO 06-19 07:40:29 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:29 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:29 habana_model_runner.py:955] [Warmup][Prompt][50/56] batch_size:1 seq_len:512 free_mem:34.58 GiB
INFO 06-19 07:40:29 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:29 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:30 habana_model_runner.py:955] [Warmup][Prompt][51/56] batch_size:2 seq_len:256 free_mem:34.58 GiB
INFO 06-19 07:40:30 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:30 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:30 habana_model_runner.py:955] [Warmup][Prompt][52/56] batch_size:4 seq_len:128 free_mem:34.58 GiB
INFO 06-19 07:40:30 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:30 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:31 habana_model_runner.py:955] [Warmup][Prompt][53/56] batch_size:1 seq_len:384 free_mem:34.58 GiB
INFO 06-19 07:40:31 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:31 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:31 habana_model_runner.py:955] [Warmup][Prompt][54/56] batch_size:1 seq_len:256 free_mem:34.58 GiB
INFO 06-19 07:40:31 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:31 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:31 habana_model_runner.py:955] [Warmup][Prompt][55/56] batch_size:2 seq_len:128 free_mem:34.58 GiB
INFO 06-19 07:40:31 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:31 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:32 habana_model_runner.py:955] [Warmup][Prompt][56/56] batch_size:1 seq_len:128 free_mem:34.58 GiB
INFO 06-19 07:40:32 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:32 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:40:32 habana_model_runner.py:955] [Warmup][Decode][1/144] batch_size:256 seq_len:2048 free_mem:34.58 GiB
INFO 06-19 07:40:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:33 habana_model_runner.py:955] [Warmup][Decode][2/144] batch_size:256 seq_len:1920 free_mem:34.58 GiB
INFO 06-19 07:40:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:33 habana_model_runner.py:955] [Warmup][Decode][3/144] batch_size:256 seq_len:1792 free_mem:34.58 GiB
INFO 06-19 07:40:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:34 habana_model_runner.py:955] [Warmup][Decode][4/144] batch_size:256 seq_len:1664 free_mem:34.57 GiB
INFO 06-19 07:40:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:35 habana_model_runner.py:955] [Warmup][Decode][5/144] batch_size:256 seq_len:1536 free_mem:34.57 GiB
INFO 06-19 07:40:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:35 habana_model_runner.py:955] [Warmup][Decode][6/144] batch_size:256 seq_len:1408 free_mem:34.57 GiB
INFO 06-19 07:40:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:36 habana_model_runner.py:955] [Warmup][Decode][7/144] batch_size:256 seq_len:1280 free_mem:34.57 GiB
INFO 06-19 07:40:36 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:37 habana_model_runner.py:955] [Warmup][Decode][8/144] batch_size:256 seq_len:1152 free_mem:34.57 GiB
INFO 06-19 07:40:37 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:38 habana_model_runner.py:955] [Warmup][Decode][9/144] batch_size:128 seq_len:2048 free_mem:34.57 GiB
INFO 06-19 07:40:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:38 habana_model_runner.py:955] [Warmup][Decode][10/144] batch_size:256 seq_len:1024 free_mem:34.57 GiB
INFO 06-19 07:40:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:39 habana_model_runner.py:955] [Warmup][Decode][11/144] batch_size:128 seq_len:1920 free_mem:34.57 GiB
INFO 06-19 07:40:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:39 habana_model_runner.py:955] [Warmup][Decode][12/144] batch_size:128 seq_len:1792 free_mem:34.57 GiB
INFO 06-19 07:40:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:40 habana_model_runner.py:955] [Warmup][Decode][13/144] batch_size:256 seq_len:896 free_mem:34.57 GiB
INFO 06-19 07:40:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:40 habana_model_runner.py:955] [Warmup][Decode][14/144] batch_size:128 seq_len:1664 free_mem:34.57 GiB
INFO 06-19 07:40:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:41 habana_model_runner.py:955] [Warmup][Decode][15/144] batch_size:128 seq_len:1536 free_mem:34.57 GiB
INFO 06-19 07:40:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:41 habana_model_runner.py:955] [Warmup][Decode][16/144] batch_size:256 seq_len:768 free_mem:34.57 GiB
INFO 06-19 07:40:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:42 habana_model_runner.py:955] [Warmup][Decode][17/144] batch_size:128 seq_len:1408 free_mem:34.57 GiB
INFO 06-19 07:40:42 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:43 habana_model_runner.py:955] [Warmup][Decode][18/144] batch_size:128 seq_len:1280 free_mem:34.57 GiB
INFO 06-19 07:40:43 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:43 habana_model_runner.py:955] [Warmup][Decode][19/144] batch_size:256 seq_len:640 free_mem:34.57 GiB
INFO 06-19 07:40:43 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:44 habana_model_runner.py:955] [Warmup][Decode][20/144] batch_size:128 seq_len:1152 free_mem:34.57 GiB
INFO 06-19 07:40:44 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:44 habana_model_runner.py:955] [Warmup][Decode][21/144] batch_size:64 seq_len:2048 free_mem:34.57 GiB
INFO 06-19 07:40:44 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:40:45 habana_model_runner.py:955] [Warmup][Decode][22/144] batch_size:128 seq_len:1024 free_mem:34.57 GiB
INFO 06-19 07:40:45 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:45 habana_model_runner.py:955] [Warmup][Decode][23/144] batch_size:256 seq_len:512 free_mem:34.57 GiB
INFO 06-19 07:40:45 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:46 habana_model_runner.py:955] [Warmup][Decode][24/144] batch_size:64 seq_len:1920 free_mem:34.57 GiB
INFO 06-19 07:40:46 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:40:46 habana_model_runner.py:955] [Warmup][Decode][25/144] batch_size:64 seq_len:1792 free_mem:34.57 GiB
INFO 06-19 07:40:46 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:40:46 habana_model_runner.py:955] [Warmup][Decode][26/144] batch_size:128 seq_len:896 free_mem:34.57 GiB
INFO 06-19 07:40:46 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:47 habana_model_runner.py:955] [Warmup][Decode][27/144] batch_size:64 seq_len:1664 free_mem:34.57 GiB
INFO 06-19 07:40:47 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:40:47 habana_model_runner.py:955] [Warmup][Decode][28/144] batch_size:64 seq_len:1536 free_mem:34.57 GiB
INFO 06-19 07:40:47 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:40:48 habana_model_runner.py:955] [Warmup][Decode][29/144] batch_size:128 seq_len:768 free_mem:34.57 GiB
INFO 06-19 07:40:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:48 habana_model_runner.py:955] [Warmup][Decode][30/144] batch_size:256 seq_len:384 free_mem:34.57 GiB
INFO 06-19 07:40:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:49 habana_model_runner.py:955] [Warmup][Decode][31/144] batch_size:64 seq_len:1408 free_mem:34.57 GiB
INFO 06-19 07:40:49 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:40:50 habana_model_runner.py:955] [Warmup][Decode][32/144] batch_size:64 seq_len:1280 free_mem:34.57 GiB
INFO 06-19 07:40:50 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:40:50 habana_model_runner.py:955] [Warmup][Decode][33/144] batch_size:128 seq_len:640 free_mem:34.57 GiB
INFO 06-19 07:40:50 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:51 habana_model_runner.py:955] [Warmup][Decode][34/144] batch_size:64 seq_len:1152 free_mem:34.57 GiB
INFO 06-19 07:40:51 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:40:51 habana_model_runner.py:955] [Warmup][Decode][35/144] batch_size:32 seq_len:2048 free_mem:34.57 GiB
INFO 06-19 07:40:51 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:40:52 habana_model_runner.py:955] [Warmup][Decode][36/144] batch_size:64 seq_len:1024 free_mem:34.57 GiB
INFO 06-19 07:40:52 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:40:52 habana_model_runner.py:955] [Warmup][Decode][37/144] batch_size:128 seq_len:512 free_mem:34.57 GiB
INFO 06-19 07:40:52 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:52 habana_model_runner.py:955] [Warmup][Decode][38/144] batch_size:256 seq_len:256 free_mem:34.57 GiB
INFO 06-19 07:40:52 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:40:53 habana_model_runner.py:955] [Warmup][Decode][39/144] batch_size:32 seq_len:1920 free_mem:34.57 GiB
INFO 06-19 07:40:53 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:40:53 habana_model_runner.py:955] [Warmup][Decode][40/144] batch_size:32 seq_len:1792 free_mem:34.57 GiB
INFO 06-19 07:40:53 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:40:54 habana_model_runner.py:955] [Warmup][Decode][41/144] batch_size:64 seq_len:896 free_mem:34.57 GiB
INFO 06-19 07:40:54 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:40:54 habana_model_runner.py:955] [Warmup][Decode][42/144] batch_size:32 seq_len:1664 free_mem:34.57 GiB
INFO 06-19 07:40:54 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:40:54 habana_model_runner.py:955] [Warmup][Decode][43/144] batch_size:32 seq_len:1536 free_mem:34.57 GiB
INFO 06-19 07:40:54 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:40:55 habana_model_runner.py:955] [Warmup][Decode][44/144] batch_size:64 seq_len:768 free_mem:34.57 GiB
INFO 06-19 07:40:55 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:40:56 habana_model_runner.py:955] [Warmup][Decode][45/144] batch_size:128 seq_len:384 free_mem:34.57 GiB
INFO 06-19 07:40:56 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:40:56 habana_model_runner.py:955] [Warmup][Decode][46/144] batch_size:32 seq_len:1408 free_mem:34.57 GiB
INFO 06-19 07:40:56 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:40:57 habana_model_runner.py:955] [Warmup][Decode][47/144] batch_size:32 seq_len:1280 free_mem:34.57 GiB
INFO 06-19 07:40:57 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:40:57 habana_model_runner.py:955] [Warmup][Decode][48/144] batch_size:64 seq_len:640 free_mem:34.57 GiB
INFO 06-19 07:40:57 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:40:58 habana_model_runner.py:955] [Warmup][Decode][49/144] batch_size:32 seq_len:1152 free_mem:34.57 GiB
INFO 06-19 07:40:58 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:40:58 habana_model_runner.py:955] [Warmup][Decode][50/144] batch_size:16 seq_len:2048 free_mem:34.57 GiB
INFO 06-19 07:40:58 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:40:59 habana_model_runner.py:955] [Warmup][Decode][51/144] batch_size:32 seq_len:1024 free_mem:34.57 GiB
INFO 06-19 07:40:59 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:40:59 habana_model_runner.py:955] [Warmup][Decode][52/144] batch_size:64 seq_len:512 free_mem:34.57 GiB
INFO 06-19 07:40:59 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:41:00 habana_model_runner.py:955] [Warmup][Decode][53/144] batch_size:128 seq_len:256 free_mem:34.57 GiB
INFO 06-19 07:41:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:41:00 habana_model_runner.py:955] [Warmup][Decode][54/144] batch_size:256 seq_len:128 free_mem:34.57 GiB
INFO 06-19 07:41:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 07:41:00 habana_model_runner.py:955] [Warmup][Decode][55/144] batch_size:16 seq_len:1920 free_mem:34.57 GiB
INFO 06-19 07:41:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:01 habana_model_runner.py:955] [Warmup][Decode][56/144] batch_size:16 seq_len:1792 free_mem:34.57 GiB
INFO 06-19 07:41:01 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:01 habana_model_runner.py:955] [Warmup][Decode][57/144] batch_size:32 seq_len:896 free_mem:34.57 GiB
INFO 06-19 07:41:01 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:41:01 habana_model_runner.py:955] [Warmup][Decode][58/144] batch_size:16 seq_len:1664 free_mem:34.57 GiB
INFO 06-19 07:41:01 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:02 habana_model_runner.py:955] [Warmup][Decode][59/144] batch_size:16 seq_len:1536 free_mem:34.57 GiB
INFO 06-19 07:41:02 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:02 habana_model_runner.py:955] [Warmup][Decode][60/144] batch_size:32 seq_len:768 free_mem:34.57 GiB
INFO 06-19 07:41:02 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:41:03 habana_model_runner.py:955] [Warmup][Decode][61/144] batch_size:64 seq_len:384 free_mem:34.57 GiB
INFO 06-19 07:41:03 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:41:03 habana_model_runner.py:955] [Warmup][Decode][62/144] batch_size:16 seq_len:1408 free_mem:34.57 GiB
INFO 06-19 07:41:03 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:04 habana_model_runner.py:955] [Warmup][Decode][63/144] batch_size:16 seq_len:1280 free_mem:34.57 GiB
INFO 06-19 07:41:04 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:04 habana_model_runner.py:955] [Warmup][Decode][64/144] batch_size:32 seq_len:640 free_mem:34.57 GiB
INFO 06-19 07:41:04 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:41:05 habana_model_runner.py:955] [Warmup][Decode][65/144] batch_size:16 seq_len:1152 free_mem:34.57 GiB
INFO 06-19 07:41:05 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:05 habana_model_runner.py:955] [Warmup][Decode][66/144] batch_size:8 seq_len:2048 free_mem:34.57 GiB
INFO 06-19 07:41:05 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:06 habana_model_runner.py:955] [Warmup][Decode][67/144] batch_size:16 seq_len:1024 free_mem:34.57 GiB
INFO 06-19 07:41:06 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:06 habana_model_runner.py:955] [Warmup][Decode][68/144] batch_size:32 seq_len:512 free_mem:34.57 GiB
INFO 06-19 07:41:06 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:41:07 habana_model_runner.py:955] [Warmup][Decode][69/144] batch_size:64 seq_len:256 free_mem:34.57 GiB
INFO 06-19 07:41:07 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:41:07 habana_model_runner.py:955] [Warmup][Decode][70/144] batch_size:128 seq_len:128 free_mem:34.57 GiB
INFO 06-19 07:41:07 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 07:41:07 habana_model_runner.py:955] [Warmup][Decode][71/144] batch_size:8 seq_len:1920 free_mem:34.57 GiB
INFO 06-19 07:41:07 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:08 habana_model_runner.py:955] [Warmup][Decode][72/144] batch_size:8 seq_len:1792 free_mem:34.57 GiB
INFO 06-19 07:41:08 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:08 habana_model_runner.py:955] [Warmup][Decode][73/144] batch_size:16 seq_len:896 free_mem:34.57 GiB
INFO 06-19 07:41:08 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:08 habana_model_runner.py:955] [Warmup][Decode][74/144] batch_size:8 seq_len:1664 free_mem:34.57 GiB
INFO 06-19 07:41:08 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:09 habana_model_runner.py:955] [Warmup][Decode][75/144] batch_size:8 seq_len:1536 free_mem:34.57 GiB
INFO 06-19 07:41:09 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:09 habana_model_runner.py:955] [Warmup][Decode][76/144] batch_size:16 seq_len:768 free_mem:34.57 GiB
INFO 06-19 07:41:09 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:10 habana_model_runner.py:955] [Warmup][Decode][77/144] batch_size:32 seq_len:384 free_mem:34.57 GiB
INFO 06-19 07:41:10 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:41:10 habana_model_runner.py:955] [Warmup][Decode][78/144] batch_size:8 seq_len:1408 free_mem:34.57 GiB
INFO 06-19 07:41:10 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:11 habana_model_runner.py:955] [Warmup][Decode][79/144] batch_size:8 seq_len:1280 free_mem:34.57 GiB
INFO 06-19 07:41:11 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:11 habana_model_runner.py:955] [Warmup][Decode][80/144] batch_size:16 seq_len:640 free_mem:34.57 GiB
INFO 06-19 07:41:11 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:12 habana_model_runner.py:955] [Warmup][Decode][81/144] batch_size:8 seq_len:1152 free_mem:34.57 GiB
INFO 06-19 07:41:12 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:12 habana_model_runner.py:955] [Warmup][Decode][82/144] batch_size:4 seq_len:2048 free_mem:34.57 GiB
INFO 06-19 07:41:12 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:13 habana_model_runner.py:955] [Warmup][Decode][83/144] batch_size:8 seq_len:1024 free_mem:34.57 GiB
INFO 06-19 07:41:13 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:13 habana_model_runner.py:955] [Warmup][Decode][84/144] batch_size:16 seq_len:512 free_mem:34.57 GiB
INFO 06-19 07:41:13 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:14 habana_model_runner.py:955] [Warmup][Decode][85/144] batch_size:32 seq_len:256 free_mem:34.57 GiB
INFO 06-19 07:41:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:41:14 habana_model_runner.py:955] [Warmup][Decode][86/144] batch_size:64 seq_len:128 free_mem:34.57 GiB
INFO 06-19 07:41:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 07:41:14 habana_model_runner.py:955] [Warmup][Decode][87/144] batch_size:4 seq_len:1920 free_mem:34.57 GiB
INFO 06-19 07:41:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:15 habana_model_runner.py:955] [Warmup][Decode][88/144] batch_size:4 seq_len:1792 free_mem:34.57 GiB
INFO 06-19 07:41:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:15 habana_model_runner.py:955] [Warmup][Decode][89/144] batch_size:8 seq_len:896 free_mem:34.57 GiB
INFO 06-19 07:41:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:15 habana_model_runner.py:955] [Warmup][Decode][90/144] batch_size:4 seq_len:1664 free_mem:34.57 GiB
INFO 06-19 07:41:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:16 habana_model_runner.py:955] [Warmup][Decode][91/144] batch_size:4 seq_len:1536 free_mem:34.57 GiB
INFO 06-19 07:41:16 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:16 habana_model_runner.py:955] [Warmup][Decode][92/144] batch_size:8 seq_len:768 free_mem:34.57 GiB
INFO 06-19 07:41:16 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:17 habana_model_runner.py:955] [Warmup][Decode][93/144] batch_size:16 seq_len:384 free_mem:34.57 GiB
INFO 06-19 07:41:17 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:17 habana_model_runner.py:955] [Warmup][Decode][94/144] batch_size:4 seq_len:1408 free_mem:34.57 GiB
INFO 06-19 07:41:17 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:18 habana_model_runner.py:955] [Warmup][Decode][95/144] batch_size:4 seq_len:1280 free_mem:34.57 GiB
INFO 06-19 07:41:18 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:18 habana_model_runner.py:955] [Warmup][Decode][96/144] batch_size:8 seq_len:640 free_mem:34.57 GiB
INFO 06-19 07:41:18 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:19 habana_model_runner.py:955] [Warmup][Decode][97/144] batch_size:4 seq_len:1152 free_mem:34.57 GiB
INFO 06-19 07:41:19 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:19 habana_model_runner.py:955] [Warmup][Decode][98/144] batch_size:2 seq_len:2048 free_mem:34.57 GiB
INFO 06-19 07:41:19 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:20 habana_model_runner.py:955] [Warmup][Decode][99/144] batch_size:4 seq_len:1024 free_mem:34.57 GiB
INFO 06-19 07:41:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:20 habana_model_runner.py:955] [Warmup][Decode][100/144] batch_size:8 seq_len:512 free_mem:34.57 GiB
INFO 06-19 07:41:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:21 habana_model_runner.py:955] [Warmup][Decode][101/144] batch_size:16 seq_len:256 free_mem:34.57 GiB
INFO 06-19 07:41:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:21 habana_model_runner.py:955] [Warmup][Decode][102/144] batch_size:32 seq_len:128 free_mem:34.57 GiB
INFO 06-19 07:41:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 07:41:21 habana_model_runner.py:955] [Warmup][Decode][103/144] batch_size:2 seq_len:1920 free_mem:34.57 GiB
INFO 06-19 07:41:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:21 habana_model_runner.py:955] [Warmup][Decode][104/144] batch_size:2 seq_len:1792 free_mem:34.57 GiB
INFO 06-19 07:41:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:22 habana_model_runner.py:955] [Warmup][Decode][105/144] batch_size:4 seq_len:896 free_mem:34.57 GiB
INFO 06-19 07:41:22 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:22 habana_model_runner.py:955] [Warmup][Decode][106/144] batch_size:2 seq_len:1664 free_mem:34.57 GiB
INFO 06-19 07:41:22 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:23 habana_model_runner.py:955] [Warmup][Decode][107/144] batch_size:2 seq_len:1536 free_mem:34.57 GiB
INFO 06-19 07:41:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:23 habana_model_runner.py:955] [Warmup][Decode][108/144] batch_size:4 seq_len:768 free_mem:34.57 GiB
INFO 06-19 07:41:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:23 habana_model_runner.py:955] [Warmup][Decode][109/144] batch_size:8 seq_len:384 free_mem:34.57 GiB
INFO 06-19 07:41:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:24 habana_model_runner.py:955] [Warmup][Decode][110/144] batch_size:2 seq_len:1408 free_mem:34.57 GiB
INFO 06-19 07:41:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:24 habana_model_runner.py:955] [Warmup][Decode][111/144] batch_size:2 seq_len:1280 free_mem:34.57 GiB
INFO 06-19 07:41:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:25 habana_model_runner.py:955] [Warmup][Decode][112/144] batch_size:4 seq_len:640 free_mem:34.57 GiB
INFO 06-19 07:41:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:25 habana_model_runner.py:955] [Warmup][Decode][113/144] batch_size:2 seq_len:1152 free_mem:34.57 GiB
INFO 06-19 07:41:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:25 habana_model_runner.py:955] [Warmup][Decode][114/144] batch_size:1 seq_len:2048 free_mem:34.57 GiB
INFO 06-19 07:41:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:26 habana_model_runner.py:955] [Warmup][Decode][115/144] batch_size:2 seq_len:1024 free_mem:34.57 GiB
INFO 06-19 07:41:26 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:26 habana_model_runner.py:955] [Warmup][Decode][116/144] batch_size:4 seq_len:512 free_mem:34.57 GiB
INFO 06-19 07:41:26 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:27 habana_model_runner.py:955] [Warmup][Decode][117/144] batch_size:8 seq_len:256 free_mem:34.57 GiB
INFO 06-19 07:41:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:27 habana_model_runner.py:955] [Warmup][Decode][118/144] batch_size:16 seq_len:128 free_mem:34.57 GiB
INFO 06-19 07:41:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 07:41:27 habana_model_runner.py:955] [Warmup][Decode][119/144] batch_size:1 seq_len:1920 free_mem:34.57 GiB
INFO 06-19 07:41:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:27 habana_model_runner.py:955] [Warmup][Decode][120/144] batch_size:1 seq_len:1792 free_mem:34.57 GiB
INFO 06-19 07:41:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:28 habana_model_runner.py:955] [Warmup][Decode][121/144] batch_size:2 seq_len:896 free_mem:34.57 GiB
INFO 06-19 07:41:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:28 habana_model_runner.py:955] [Warmup][Decode][122/144] batch_size:1 seq_len:1664 free_mem:34.57 GiB
INFO 06-19 07:41:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:28 habana_model_runner.py:955] [Warmup][Decode][123/144] batch_size:1 seq_len:1536 free_mem:34.57 GiB
INFO 06-19 07:41:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:29 habana_model_runner.py:955] [Warmup][Decode][124/144] batch_size:2 seq_len:768 free_mem:34.57 GiB
INFO 06-19 07:41:29 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:29 habana_model_runner.py:955] [Warmup][Decode][125/144] batch_size:4 seq_len:384 free_mem:34.57 GiB
INFO 06-19 07:41:29 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:29 habana_model_runner.py:955] [Warmup][Decode][126/144] batch_size:1 seq_len:1408 free_mem:34.57 GiB
INFO 06-19 07:41:29 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:30 habana_model_runner.py:955] [Warmup][Decode][127/144] batch_size:1 seq_len:1280 free_mem:34.57 GiB
INFO 06-19 07:41:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:30 habana_model_runner.py:955] [Warmup][Decode][128/144] batch_size:2 seq_len:640 free_mem:34.57 GiB
INFO 06-19 07:41:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:30 habana_model_runner.py:955] [Warmup][Decode][129/144] batch_size:1 seq_len:1152 free_mem:34.57 GiB
INFO 06-19 07:41:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:31 habana_model_runner.py:955] [Warmup][Decode][130/144] batch_size:1 seq_len:1024 free_mem:34.57 GiB
INFO 06-19 07:41:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:31 habana_model_runner.py:955] [Warmup][Decode][131/144] batch_size:2 seq_len:512 free_mem:34.57 GiB
INFO 06-19 07:41:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:31 habana_model_runner.py:955] [Warmup][Decode][132/144] batch_size:4 seq_len:256 free_mem:34.57 GiB
INFO 06-19 07:41:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:32 habana_model_runner.py:955] [Warmup][Decode][133/144] batch_size:8 seq_len:128 free_mem:34.57 GiB
INFO 06-19 07:41:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 07:41:32 habana_model_runner.py:955] [Warmup][Decode][134/144] batch_size:1 seq_len:896 free_mem:34.57 GiB
INFO 06-19 07:41:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:32 habana_model_runner.py:955] [Warmup][Decode][135/144] batch_size:1 seq_len:768 free_mem:34.57 GiB
INFO 06-19 07:41:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:32 habana_model_runner.py:955] [Warmup][Decode][136/144] batch_size:2 seq_len:384 free_mem:34.57 GiB
INFO 06-19 07:41:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:32 habana_model_runner.py:955] [Warmup][Decode][137/144] batch_size:1 seq_len:640 free_mem:34.57 GiB
INFO 06-19 07:41:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:33 habana_model_runner.py:955] [Warmup][Decode][138/144] batch_size:1 seq_len:512 free_mem:34.57 GiB
INFO 06-19 07:41:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:33 habana_model_runner.py:955] [Warmup][Decode][139/144] batch_size:2 seq_len:256 free_mem:34.57 GiB
INFO 06-19 07:41:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:33 habana_model_runner.py:955] [Warmup][Decode][140/144] batch_size:4 seq_len:128 free_mem:34.57 GiB
INFO 06-19 07:41:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 07:41:33 habana_model_runner.py:955] [Warmup][Decode][141/144] batch_size:1 seq_len:384 free_mem:34.57 GiB
INFO 06-19 07:41:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:34 habana_model_runner.py:955] [Warmup][Decode][142/144] batch_size:1 seq_len:256 free_mem:34.57 GiB
INFO 06-19 07:41:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:34 habana_model_runner.py:955] [Warmup][Decode][143/144] batch_size:2 seq_len:128 free_mem:34.57 GiB
INFO 06-19 07:41:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 07:41:34 habana_model_runner.py:955] [Warmup][Decode][144/144] batch_size:1 seq_len:128 free_mem:34.57 GiB
INFO 06-19 07:41:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 07:41:34 habana_model_runner.py:966] Skipping prompt graph warmup...
INFO 06-19 07:41:34 habana_model_runner.py:955] [Warmup][Graph/Decode][1/144] batch_size:256 seq_len:128 free_mem:34.57 GiB
INFO 06-19 07:41:34 habana_model_runner.py:955] [Warmup][Graph/Decode][2/144] batch_size:256 seq_len:256 free_mem:33.99 GiB
INFO 06-19 07:41:35 habana_model_runner.py:955] [Warmup][Graph/Decode][3/144] batch_size:256 seq_len:384 free_mem:33.41 GiB
INFO 06-19 07:41:35 habana_model_runner.py:955] [Warmup][Graph/Decode][4/144] batch_size:256 seq_len:512 free_mem:32.83 GiB
INFO 06-19 07:41:36 habana_model_runner.py:955] [Warmup][Graph/Decode][5/144] batch_size:256 seq_len:640 free_mem:32.25 GiB
INFO 06-19 07:41:36 habana_model_runner.py:955] [Warmup][Graph/Decode][6/144] batch_size:256 seq_len:768 free_mem:31.67 GiB
INFO 06-19 07:41:37 habana_model_runner.py:955] [Warmup][Graph/Decode][7/144] batch_size:256 seq_len:896 free_mem:31.09 GiB
INFO 06-19 07:41:37 habana_model_runner.py:955] [Warmup][Graph/Decode][8/144] batch_size:256 seq_len:1024 free_mem:30.51 GiB
INFO 06-19 07:41:38 habana_model_runner.py:955] [Warmup][Graph/Decode][9/144] batch_size:256 seq_len:1152 free_mem:29.93 GiB
INFO 06-19 07:41:38 habana_model_runner.py:955] [Warmup][Graph/Decode][10/144] batch_size:256 seq_len:1280 free_mem:29.34 GiB
INFO 06-19 07:41:39 habana_model_runner.py:955] [Warmup][Graph/Decode][11/144] batch_size:256 seq_len:1408 free_mem:28.76 GiB
INFO 06-19 07:41:40 habana_model_runner.py:955] [Warmup][Graph/Decode][12/144] batch_size:256 seq_len:1536 free_mem:28.18 GiB
INFO 06-19 07:41:40 habana_model_runner.py:955] [Warmup][Graph/Decode][13/144] batch_size:256 seq_len:1664 free_mem:27.59 GiB
INFO 06-19 07:41:41 habana_model_runner.py:955] [Warmup][Graph/Decode][14/144] batch_size:256 seq_len:1792 free_mem:27.01 GiB
INFO 06-19 07:41:42 habana_model_runner.py:955] [Warmup][Graph/Decode][15/144] batch_size:256 seq_len:1920 free_mem:26.42 GiB
INFO 06-19 07:41:43 habana_model_runner.py:955] [Warmup][Graph/Decode][16/144] batch_size:256 seq_len:2048 free_mem:25.84 GiB
INFO 06-19 07:41:43 habana_model_runner.py:955] [Warmup][Graph/Decode][17/144] batch_size:128 seq_len:128 free_mem:25.25 GiB
INFO 06-19 07:41:44 habana_model_runner.py:955] [Warmup][Graph/Decode][18/144] batch_size:128 seq_len:256 free_mem:24.96 GiB
INFO 06-19 07:41:44 habana_model_runner.py:955] [Warmup][Graph/Decode][19/144] batch_size:128 seq_len:384 free_mem:24.67 GiB
INFO 06-19 07:41:44 habana_model_runner.py:955] [Warmup][Graph/Decode][20/144] batch_size:128 seq_len:512 free_mem:24.38 GiB
INFO 06-19 07:41:45 habana_model_runner.py:955] [Warmup][Graph/Decode][21/144] batch_size:128 seq_len:640 free_mem:24.09 GiB
INFO 06-19 07:41:45 habana_model_runner.py:955] [Warmup][Graph/Decode][22/144] batch_size:128 seq_len:768 free_mem:23.8 GiB
INFO 06-19 07:41:46 habana_model_runner.py:955] [Warmup][Graph/Decode][23/144] batch_size:128 seq_len:896 free_mem:23.51 GiB
INFO 06-19 07:41:46 habana_model_runner.py:955] [Warmup][Graph/Decode][24/144] batch_size:128 seq_len:1024 free_mem:23.22 GiB
INFO 06-19 07:41:46 habana_model_runner.py:955] [Warmup][Graph/Decode][25/144] batch_size:128 seq_len:1152 free_mem:22.93 GiB
INFO 06-19 07:41:47 habana_model_runner.py:955] [Warmup][Graph/Decode][26/144] batch_size:128 seq_len:1280 free_mem:22.64 GiB
INFO 06-19 07:41:47 habana_model_runner.py:955] [Warmup][Graph/Decode][27/144] batch_size:128 seq_len:1408 free_mem:22.35 GiB
INFO 06-19 07:41:48 habana_model_runner.py:955] [Warmup][Graph/Decode][28/144] batch_size:128 seq_len:1536 free_mem:22.06 GiB
INFO 06-19 07:41:48 habana_model_runner.py:955] [Warmup][Graph/Decode][29/144] batch_size:128 seq_len:1664 free_mem:21.77 GiB
INFO 06-19 07:41:49 habana_model_runner.py:955] [Warmup][Graph/Decode][30/144] batch_size:128 seq_len:1792 free_mem:21.48 GiB
INFO 06-19 07:41:49 habana_model_runner.py:955] [Warmup][Graph/Decode][31/144] batch_size:128 seq_len:1920 free_mem:21.19 GiB
INFO 06-19 07:41:50 habana_model_runner.py:955] [Warmup][Graph/Decode][32/144] batch_size:128 seq_len:2048 free_mem:20.9 GiB
INFO 06-19 07:41:51 habana_model_runner.py:955] [Warmup][Graph/Decode][33/144] batch_size:64 seq_len:128 free_mem:20.61 GiB
INFO 06-19 07:41:51 habana_model_runner.py:955] [Warmup][Graph/Decode][34/144] batch_size:64 seq_len:256 free_mem:20.46 GiB
INFO 06-19 07:41:51 habana_model_runner.py:955] [Warmup][Graph/Decode][35/144] batch_size:64 seq_len:384 free_mem:20.32 GiB
INFO 06-19 07:41:52 habana_model_runner.py:955] [Warmup][Graph/Decode][36/144] batch_size:64 seq_len:512 free_mem:20.17 GiB
INFO 06-19 07:41:52 habana_model_runner.py:955] [Warmup][Graph/Decode][37/144] batch_size:64 seq_len:640 free_mem:20.03 GiB
INFO 06-19 07:41:52 habana_model_runner.py:955] [Warmup][Graph/Decode][38/144] batch_size:64 seq_len:768 free_mem:19.88 GiB
INFO 06-19 07:41:53 habana_model_runner.py:955] [Warmup][Graph/Decode][39/144] batch_size:64 seq_len:896 free_mem:19.74 GiB
INFO 06-19 07:41:53 habana_model_runner.py:955] [Warmup][Graph/Decode][40/144] batch_size:64 seq_len:1024 free_mem:19.59 GiB
INFO 06-19 07:41:53 habana_model_runner.py:955] [Warmup][Graph/Decode][41/144] batch_size:64 seq_len:1152 free_mem:19.45 GiB
INFO 06-19 07:41:54 habana_model_runner.py:955] [Warmup][Graph/Decode][42/144] batch_size:64 seq_len:1280 free_mem:19.3 GiB
INFO 06-19 07:41:54 habana_model_runner.py:955] [Warmup][Graph/Decode][43/144] batch_size:64 seq_len:1408 free_mem:19.16 GiB
INFO 06-19 07:41:55 habana_model_runner.py:955] [Warmup][Graph/Decode][44/144] batch_size:64 seq_len:1536 free_mem:19.01 GiB
INFO 06-19 07:41:55 habana_model_runner.py:955] [Warmup][Graph/Decode][45/144] batch_size:64 seq_len:1664 free_mem:18.87 GiB
INFO 06-19 07:41:56 habana_model_runner.py:955] [Warmup][Graph/Decode][46/144] batch_size:64 seq_len:1792 free_mem:18.72 GiB
INFO 06-19 07:41:56 habana_model_runner.py:955] [Warmup][Graph/Decode][47/144] batch_size:64 seq_len:1920 free_mem:18.58 GiB
INFO 06-19 07:41:56 habana_model_runner.py:955] [Warmup][Graph/Decode][48/144] batch_size:64 seq_len:2048 free_mem:18.43 GiB
INFO 06-19 07:41:57 habana_model_runner.py:955] [Warmup][Graph/Decode][49/144] batch_size:32 seq_len:128 free_mem:18.29 GiB
INFO 06-19 07:41:57 habana_model_runner.py:955] [Warmup][Graph/Decode][50/144] batch_size:32 seq_len:256 free_mem:18.22 GiB
INFO 06-19 07:41:58 habana_model_runner.py:955] [Warmup][Graph/Decode][51/144] batch_size:32 seq_len:384 free_mem:18.14 GiB
INFO 06-19 07:41:58 habana_model_runner.py:955] [Warmup][Graph/Decode][52/144] batch_size:32 seq_len:512 free_mem:18.07 GiB
INFO 06-19 07:41:58 habana_model_runner.py:955] [Warmup][Graph/Decode][53/144] batch_size:32 seq_len:640 free_mem:18 GiB
INFO 06-19 07:41:59 habana_model_runner.py:955] [Warmup][Graph/Decode][54/144] batch_size:32 seq_len:768 free_mem:17.93 GiB
INFO 06-19 07:41:59 habana_model_runner.py:955] [Warmup][Graph/Decode][55/144] batch_size:32 seq_len:896 free_mem:17.85 GiB
INFO 06-19 07:41:59 habana_model_runner.py:955] [Warmup][Graph/Decode][56/144] batch_size:32 seq_len:1024 free_mem:17.78 GiB
INFO 06-19 07:42:00 habana_model_runner.py:955] [Warmup][Graph/Decode][57/144] batch_size:32 seq_len:1152 free_mem:17.71 GiB
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1280, memory estimated: 78028018.23873146
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1408, memory estimated: 78028018.23873146
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1536, memory estimated: 78028018.23873146
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1664, memory estimated: 78028018.23873146
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1792, memory estimated: 78028018.23873146
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1920, memory estimated: 78028018.23873146
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 2048, memory estimated: 78028018.23873146
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 128, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 256, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 384, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 512, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 640, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 768, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 896, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1024, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1152, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1280, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1408, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1536, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1664, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1792, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1920, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 2048, memory estimated: 39014009.11936573
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 128, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 256, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 384, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 512, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 640, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 768, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 896, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1024, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1152, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1280, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1408, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1536, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1664, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1792, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1920, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 2048, memory estimated: 19507004.559682865
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 128, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 256, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 384, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 512, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 640, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 768, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 896, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1024, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1152, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1280, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1408, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1536, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1664, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1792, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1920, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 2048, memory estimated: 9753502.279841432
INFO 06-19 07:42:00 habana_model_runner.py:955] [Warmup][Graph/Decode][113/144] batch_size:2 seq_len:128 free_mem:17.64 GiB
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 256, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 384, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 512, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 640, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 768, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 896, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1024, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1152, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1280, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1408, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1536, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1664, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1792, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1920, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 2048, memory estimated: 4876748.269677089
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 128, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 256, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 384, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 512, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 640, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 768, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 896, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1024, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1152, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1280, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1408, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1536, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1664, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1792, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1920, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 2048, memory estimated: 2438374.1348385443
INFO 06-19 07:42:00 habana_model_runner.py:1000] Graph/Decode captured:58 (40.3%) used_mem:16.94 GiB buckets:[(2, 128), (32, 128), (32, 256), (32, 384), (32, 512), (32, 640), (32, 768), (32, 896), (32, 1024), (32, 1152), (64, 128), (64, 256), (64, 384), (64, 512), (64, 640), (64, 768), (64, 896), (64, 1024), (64, 1152), (64, 1280), (64, 1408), (64, 1536), (64, 1664), (64, 1792), (64, 1920), (64, 2048), (128, 128), (128, 256), (128, 384), (128, 512), (128, 640), (128, 768), (128, 896), (128, 1024), (128, 1152), (128, 1280), (128, 1408), (128, 1536), (128, 1664), (128, 1792), (128, 1920), (128, 2048), (256, 128), (256, 256), (256, 384), (256, 512), (256, 640), (256, 768), (256, 896), (256, 1024), (256, 1152), (256, 1280), (256, 1408), (256, 1536), (256, 1664), (256, 1792), (256, 1920), (256, 2048)]
INFO 06-19 07:42:00 habana_model_runner.py:1028] Warmup finished in 148 secs, allocated 16.95 GiB of device memory
INFO 06-19 07:42:00 habana_executor.py:83] init_cache_engine took 57.53 GiB of device memory (76.99 GiB/94.62 GiB used) and 1.335 GiB of host memory (9.65 GiB/108.1 GiB used)
INFO 06-19 07:42:00 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:42:01 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:42:01 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 07:42:02 habana_model_runner.py:313] not use graph for prompt...
Throughput: 2.20 requests/s, 2528.90 tokens/s
