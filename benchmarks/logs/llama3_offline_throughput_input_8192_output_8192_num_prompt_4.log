Namespace(backend='vllm', dataset=None, input_len=8192, output_len=8192, model='meta-llama/Meta-Llama-3-8B', tokenizer='meta-llama/Meta-Llama-3-8B', quantization=None, tensor_parallel_size=1, n=1, use_beam_search=False, num_prompts=4, seed=0, hf_max_batch_size=None, trust_remote_code=False, max_model_len=None, dtype='bfloat16', gpu_memory_utilization=0.9, enforce_eager=False, kv_cache_dtype='auto', quantization_param_path=None, device='hpu', enable_prefix_caching=False, enable_chunked_prefill=False, max_num_batched_tokens=None, download_dir=None)
INFO 06-19 08:15:07 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='meta-llama/Meta-Llama-3-8B', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=hpu, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=meta-llama/Meta-Llama-3-8B)
INFO 06-19 08:15:08 profiler.py:59] Profiler enabled for: vllm-instance-fdf89724af1641c1ae42bbcf531586ab
WARNING 06-19 08:15:08 utils.py:454] Pin memory is not supported on HPU.
INFO 06-19 08:15:08 selector.py:52] Using HabanaAttention backend.
INFO 06-19 08:15:08 habana_model_runner.py:328] Prompt bucket config (min, step, max_warmup) bs:[1, 32, 64], seq:[128, 128, 1024]
INFO 06-19 08:15:08 habana_model_runner.py:330] Generated 56 prompt buckets: [(1, 128), (1, 256), (1, 384), (1, 512), (1, 640), (1, 768), (1, 896), (1, 1024), (2, 128), (2, 256), (2, 384), (2, 512), (2, 640), (2, 768), (2, 896), (2, 1024), (4, 128), (4, 256), (4, 384), (4, 512), (4, 640), (4, 768), (4, 896), (4, 1024), (8, 128), (8, 256), (8, 384), (8, 512), (8, 640), (8, 768), (8, 896), (8, 1024), (16, 128), (16, 256), (16, 384), (16, 512), (16, 640), (16, 768), (16, 896), (16, 1024), (32, 128), (32, 256), (32, 384), (32, 512), (32, 640), (32, 768), (32, 896), (32, 1024), (64, 128), (64, 256), (64, 384), (64, 512), (64, 640), (64, 768), (64, 896), (64, 1024)]
INFO 06-19 08:15:08 habana_model_runner.py:332] Decode bucket config (min, step, max_warmup) bs:[1, 128, 256], seq:[128, 128, 8192]
INFO 06-19 08:15:08 habana_model_runner.py:334] Generated 576 decode buckets: [(1, 128), (1, 256), (1, 384), (1, 512), (1, 640), (1, 768), (1, 896), (1, 1024), (1, 1152), (1, 1280), (1, 1408), (1, 1536), (1, 1664), (1, 1792), (1, 1920), (1, 2048), (1, 2176), (1, 2304), (1, 2432), (1, 2560), (1, 2688), (1, 2816), (1, 2944), (1, 3072), (1, 3200), (1, 3328), (1, 3456), (1, 3584), (1, 3712), (1, 3840), (1, 3968), (1, 4096), (1, 4224), (1, 4352), (1, 4480), (1, 4608), (1, 4736), (1, 4864), (1, 4992), (1, 5120), (1, 5248), (1, 5376), (1, 5504), (1, 5632), (1, 5760), (1, 5888), (1, 6016), (1, 6144), (1, 6272), (1, 6400), (1, 6528), (1, 6656), (1, 6784), (1, 6912), (1, 7040), (1, 7168), (1, 7296), (1, 7424), (1, 7552), (1, 7680), (1, 7808), (1, 7936), (1, 8064), (1, 8192), (2, 128), (2, 256), (2, 384), (2, 512), (2, 640), (2, 768), (2, 896), (2, 1024), (2, 1152), (2, 1280), (2, 1408), (2, 1536), (2, 1664), (2, 1792), (2, 1920), (2, 2048), (2, 2176), (2, 2304), (2, 2432), (2, 2560), (2, 2688), (2, 2816), (2, 2944), (2, 3072), (2, 3200), (2, 3328), (2, 3456), (2, 3584), (2, 3712), (2, 3840), (2, 3968), (2, 4096), (2, 4224), (2, 4352), (2, 4480), (2, 4608), (2, 4736), (2, 4864), (2, 4992), (2, 5120), (2, 5248), (2, 5376), (2, 5504), (2, 5632), (2, 5760), (2, 5888), (2, 6016), (2, 6144), (2, 6272), (2, 6400), (2, 6528), (2, 6656), (2, 6784), (2, 6912), (2, 7040), (2, 7168), (2, 7296), (2, 7424), (2, 7552), (2, 7680), (2, 7808), (2, 7936), (2, 8064), (2, 8192), (4, 128), (4, 256), (4, 384), (4, 512), (4, 640), (4, 768), (4, 896), (4, 1024), (4, 1152), (4, 1280), (4, 1408), (4, 1536), (4, 1664), (4, 1792), (4, 1920), (4, 2048), (4, 2176), (4, 2304), (4, 2432), (4, 2560), (4, 2688), (4, 2816), (4, 2944), (4, 3072), (4, 3200), (4, 3328), (4, 3456), (4, 3584), (4, 3712), (4, 3840), (4, 3968), (4, 4096), (4, 4224), (4, 4352), (4, 4480), (4, 4608), (4, 4736), (4, 4864), (4, 4992), (4, 5120), (4, 5248), (4, 5376), (4, 5504), (4, 5632), (4, 5760), (4, 5888), (4, 6016), (4, 6144), (4, 6272), (4, 6400), (4, 6528), (4, 6656), (4, 6784), (4, 6912), (4, 7040), (4, 7168), (4, 7296), (4, 7424), (4, 7552), (4, 7680), (4, 7808), (4, 7936), (4, 8064), (4, 8192), (8, 128), (8, 256), (8, 384), (8, 512), (8, 640), (8, 768), (8, 896), (8, 1024), (8, 1152), (8, 1280), (8, 1408), (8, 1536), (8, 1664), (8, 1792), (8, 1920), (8, 2048), (8, 2176), (8, 2304), (8, 2432), (8, 2560), (8, 2688), (8, 2816), (8, 2944), (8, 3072), (8, 3200), (8, 3328), (8, 3456), (8, 3584), (8, 3712), (8, 3840), (8, 3968), (8, 4096), (8, 4224), (8, 4352), (8, 4480), (8, 4608), (8, 4736), (8, 4864), (8, 4992), (8, 5120), (8, 5248), (8, 5376), (8, 5504), (8, 5632), (8, 5760), (8, 5888), (8, 6016), (8, 6144), (8, 6272), (8, 6400), (8, 6528), (8, 6656), (8, 6784), (8, 6912), (8, 7040), (8, 7168), (8, 7296), (8, 7424), (8, 7552), (8, 7680), (8, 7808), (8, 7936), (8, 8064), (8, 8192), (16, 128), (16, 256), (16, 384), (16, 512), (16, 640), (16, 768), (16, 896), (16, 1024), (16, 1152), (16, 1280), (16, 1408), (16, 1536), (16, 1664), (16, 1792), (16, 1920), (16, 2048), (16, 2176), (16, 2304), (16, 2432), (16, 2560), (16, 2688), (16, 2816), (16, 2944), (16, 3072), (16, 3200), (16, 3328), (16, 3456), (16, 3584), (16, 3712), (16, 3840), (16, 3968), (16, 4096), (16, 4224), (16, 4352), (16, 4480), (16, 4608), (16, 4736), (16, 4864), (16, 4992), (16, 5120), (16, 5248), (16, 5376), (16, 5504), (16, 5632), (16, 5760), (16, 5888), (16, 6016), (16, 6144), (16, 6272), (16, 6400), (16, 6528), (16, 6656), (16, 6784), (16, 6912), (16, 7040), (16, 7168), (16, 7296), (16, 7424), (16, 7552), (16, 7680), (16, 7808), (16, 7936), (16, 8064), (16, 8192), (32, 128), (32, 256), (32, 384), (32, 512), (32, 640), (32, 768), (32, 896), (32, 1024), (32, 1152), (32, 1280), (32, 1408), (32, 1536), (32, 1664), (32, 1792), (32, 1920), (32, 2048), (32, 2176), (32, 2304), (32, 2432), (32, 2560), (32, 2688), (32, 2816), (32, 2944), (32, 3072), (32, 3200), (32, 3328), (32, 3456), (32, 3584), (32, 3712), (32, 3840), (32, 3968), (32, 4096), (32, 4224), (32, 4352), (32, 4480), (32, 4608), (32, 4736), (32, 4864), (32, 4992), (32, 5120), (32, 5248), (32, 5376), (32, 5504), (32, 5632), (32, 5760), (32, 5888), (32, 6016), (32, 6144), (32, 6272), (32, 6400), (32, 6528), (32, 6656), (32, 6784), (32, 6912), (32, 7040), (32, 7168), (32, 7296), (32, 7424), (32, 7552), (32, 7680), (32, 7808), (32, 7936), (32, 8064), (32, 8192), (64, 128), (64, 256), (64, 384), (64, 512), (64, 640), (64, 768), (64, 896), (64, 1024), (64, 1152), (64, 1280), (64, 1408), (64, 1536), (64, 1664), (64, 1792), (64, 1920), (64, 2048), (64, 2176), (64, 2304), (64, 2432), (64, 2560), (64, 2688), (64, 2816), (64, 2944), (64, 3072), (64, 3200), (64, 3328), (64, 3456), (64, 3584), (64, 3712), (64, 3840), (64, 3968), (64, 4096), (64, 4224), (64, 4352), (64, 4480), (64, 4608), (64, 4736), (64, 4864), (64, 4992), (64, 5120), (64, 5248), (64, 5376), (64, 5504), (64, 5632), (64, 5760), (64, 5888), (64, 6016), (64, 6144), (64, 6272), (64, 6400), (64, 6528), (64, 6656), (64, 6784), (64, 6912), (64, 7040), (64, 7168), (64, 7296), (64, 7424), (64, 7552), (64, 7680), (64, 7808), (64, 7936), (64, 8064), (64, 8192), (128, 128), (128, 256), (128, 384), (128, 512), (128, 640), (128, 768), (128, 896), (128, 1024), (128, 1152), (128, 1280), (128, 1408), (128, 1536), (128, 1664), (128, 1792), (128, 1920), (128, 2048), (128, 2176), (128, 2304), (128, 2432), (128, 2560), (128, 2688), (128, 2816), (128, 2944), (128, 3072), (128, 3200), (128, 3328), (128, 3456), (128, 3584), (128, 3712), (128, 3840), (128, 3968), (128, 4096), (128, 4224), (128, 4352), (128, 4480), (128, 4608), (128, 4736), (128, 4864), (128, 4992), (128, 5120), (128, 5248), (128, 5376), (128, 5504), (128, 5632), (128, 5760), (128, 5888), (128, 6016), (128, 6144), (128, 6272), (128, 6400), (128, 6528), (128, 6656), (128, 6784), (128, 6912), (128, 7040), (128, 7168), (128, 7296), (128, 7424), (128, 7552), (128, 7680), (128, 7808), (128, 7936), (128, 8064), (128, 8192), (256, 128), (256, 256), (256, 384), (256, 512), (256, 640), (256, 768), (256, 896), (256, 1024), (256, 1152), (256, 1280), (256, 1408), (256, 1536), (256, 1664), (256, 1792), (256, 1920), (256, 2048), (256, 2176), (256, 2304), (256, 2432), (256, 2560), (256, 2688), (256, 2816), (256, 2944), (256, 3072), (256, 3200), (256, 3328), (256, 3456), (256, 3584), (256, 3712), (256, 3840), (256, 3968), (256, 4096), (256, 4224), (256, 4352), (256, 4480), (256, 4608), (256, 4736), (256, 4864), (256, 4992), (256, 5120), (256, 5248), (256, 5376), (256, 5504), (256, 5632), (256, 5760), (256, 5888), (256, 6016), (256, 6144), (256, 6272), (256, 6400), (256, 6528), (256, 6656), (256, 6784), (256, 6912), (256, 7040), (256, 7168), (256, 7296), (256, 7424), (256, 7552), (256, 7680), (256, 7808), (256, 7936), (256, 8064), (256, 8192)]
INFO 06-19 08:15:11 weight_utils.py:199] Using model weights format ['*.safetensors']
INFO 06-19 08:15:14 habana_model_runner.py:284] Pre-loading model weights on hpu:0 took 14.96 GiB of device memory (14.97 GiB/94.62 GiB used) and 22.76 MiB of host memory (7.753 GiB/108.1 GiB used)
INFO 06-19 08:15:14 habana_model_runner.py:289] Wrapping in HPU Graph took 0 B of device memory (14.97 GiB/94.62 GiB used) and 0 B of host memory (7.753 GiB/108.1 GiB used)
INFO 06-19 08:15:14 habana_model_runner.py:292] Loading model weights took in total 14.96 GiB of device memory (14.97 GiB/94.62 GiB used) and 22.76 MiB of host memory (7.753 GiB/108.1 GiB used)
INFO 06-19 08:15:14 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:15 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:15 pynccl_utils.py:17] Failed to import NCCL library: NCCL only supports CUDA and ROCm backends.
INFO 06-19 08:15:15 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
INFO 06-19 08:15:19 habana_executor.py:78] # HPU blocks: 2597, # CPU blocks: 256
INFO 06-19 08:15:19 habana_model_runner.py:955] [Warmup][Prompt][1/56] batch_size:64 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 08:15:19 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:19 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:23 habana_model_runner.py:955] [Warmup][Prompt][2/56] batch_size:64 seq_len:896 free_mem:34.58 GiB
INFO 06-19 08:15:23 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:23 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:27 habana_model_runner.py:955] [Warmup][Prompt][3/56] batch_size:64 seq_len:768 free_mem:34.58 GiB
INFO 06-19 08:15:27 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:27 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:31 habana_model_runner.py:955] [Warmup][Prompt][4/56] batch_size:64 seq_len:640 free_mem:34.58 GiB
INFO 06-19 08:15:31 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:31 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:34 habana_model_runner.py:955] [Warmup][Prompt][5/56] batch_size:32 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 08:15:34 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:34 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:36 habana_model_runner.py:955] [Warmup][Prompt][6/56] batch_size:64 seq_len:512 free_mem:34.58 GiB
INFO 06-19 08:15:36 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:36 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:39 habana_model_runner.py:955] [Warmup][Prompt][7/56] batch_size:32 seq_len:896 free_mem:34.58 GiB
INFO 06-19 08:15:39 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:39 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:41 habana_model_runner.py:955] [Warmup][Prompt][8/56] batch_size:32 seq_len:768 free_mem:34.58 GiB
INFO 06-19 08:15:41 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:41 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:43 habana_model_runner.py:955] [Warmup][Prompt][9/56] batch_size:64 seq_len:384 free_mem:34.58 GiB
INFO 06-19 08:15:43 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:43 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:45 habana_model_runner.py:955] [Warmup][Prompt][10/56] batch_size:32 seq_len:640 free_mem:34.58 GiB
INFO 06-19 08:15:45 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:45 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:47 habana_model_runner.py:955] [Warmup][Prompt][11/56] batch_size:16 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 08:15:47 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:47 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:48 habana_model_runner.py:955] [Warmup][Prompt][12/56] batch_size:32 seq_len:512 free_mem:34.58 GiB
INFO 06-19 08:15:48 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:48 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:50 habana_model_runner.py:955] [Warmup][Prompt][13/56] batch_size:64 seq_len:256 free_mem:34.58 GiB
INFO 06-19 08:15:50 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:50 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:51 habana_model_runner.py:955] [Warmup][Prompt][14/56] batch_size:16 seq_len:896 free_mem:34.58 GiB
INFO 06-19 08:15:51 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:51 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:52 habana_model_runner.py:955] [Warmup][Prompt][15/56] batch_size:16 seq_len:768 free_mem:34.58 GiB
INFO 06-19 08:15:52 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:52 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:53 habana_model_runner.py:955] [Warmup][Prompt][16/56] batch_size:32 seq_len:384 free_mem:34.58 GiB
INFO 06-19 08:15:53 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:53 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:55 habana_model_runner.py:955] [Warmup][Prompt][17/56] batch_size:16 seq_len:640 free_mem:34.58 GiB
INFO 06-19 08:15:55 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:55 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:56 habana_model_runner.py:955] [Warmup][Prompt][18/56] batch_size:8 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 08:15:56 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:56 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:57 habana_model_runner.py:955] [Warmup][Prompt][19/56] batch_size:16 seq_len:512 free_mem:34.58 GiB
INFO 06-19 08:15:57 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:57 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:58 habana_model_runner.py:955] [Warmup][Prompt][20/56] batch_size:32 seq_len:256 free_mem:34.58 GiB
INFO 06-19 08:15:58 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:58 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:58 habana_model_runner.py:955] [Warmup][Prompt][21/56] batch_size:64 seq_len:128 free_mem:34.58 GiB
INFO 06-19 08:15:58 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:58 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:59 habana_model_runner.py:955] [Warmup][Prompt][22/56] batch_size:8 seq_len:896 free_mem:34.58 GiB
INFO 06-19 08:15:59 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:15:59 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:00 habana_model_runner.py:955] [Warmup][Prompt][23/56] batch_size:8 seq_len:768 free_mem:34.58 GiB
INFO 06-19 08:16:00 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:00 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:01 habana_model_runner.py:955] [Warmup][Prompt][24/56] batch_size:16 seq_len:384 free_mem:34.58 GiB
INFO 06-19 08:16:01 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:01 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:02 habana_model_runner.py:955] [Warmup][Prompt][25/56] batch_size:8 seq_len:640 free_mem:34.58 GiB
INFO 06-19 08:16:02 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:02 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:03 habana_model_runner.py:955] [Warmup][Prompt][26/56] batch_size:4 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 08:16:03 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:03 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:03 habana_model_runner.py:955] [Warmup][Prompt][27/56] batch_size:8 seq_len:512 free_mem:34.58 GiB
INFO 06-19 08:16:03 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:03 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:04 habana_model_runner.py:955] [Warmup][Prompt][28/56] batch_size:16 seq_len:256 free_mem:34.58 GiB
INFO 06-19 08:16:04 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:04 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:05 habana_model_runner.py:955] [Warmup][Prompt][29/56] batch_size:32 seq_len:128 free_mem:34.58 GiB
INFO 06-19 08:16:05 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:05 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:05 habana_model_runner.py:955] [Warmup][Prompt][30/56] batch_size:4 seq_len:896 free_mem:34.58 GiB
INFO 06-19 08:16:05 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:05 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:06 habana_model_runner.py:955] [Warmup][Prompt][31/56] batch_size:4 seq_len:768 free_mem:34.58 GiB
INFO 06-19 08:16:06 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:06 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:06 habana_model_runner.py:955] [Warmup][Prompt][32/56] batch_size:8 seq_len:384 free_mem:34.58 GiB
INFO 06-19 08:16:06 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:06 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:07 habana_model_runner.py:955] [Warmup][Prompt][33/56] batch_size:4 seq_len:640 free_mem:34.58 GiB
INFO 06-19 08:16:07 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:07 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:07 habana_model_runner.py:955] [Warmup][Prompt][34/56] batch_size:2 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 08:16:07 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:07 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:08 habana_model_runner.py:955] [Warmup][Prompt][35/56] batch_size:4 seq_len:512 free_mem:34.58 GiB
INFO 06-19 08:16:08 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:08 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:09 habana_model_runner.py:955] [Warmup][Prompt][36/56] batch_size:8 seq_len:256 free_mem:34.58 GiB
INFO 06-19 08:16:09 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:09 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:09 habana_model_runner.py:955] [Warmup][Prompt][37/56] batch_size:16 seq_len:128 free_mem:34.58 GiB
INFO 06-19 08:16:09 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:09 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:10 habana_model_runner.py:955] [Warmup][Prompt][38/56] batch_size:2 seq_len:896 free_mem:34.58 GiB
INFO 06-19 08:16:10 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:10 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:10 habana_model_runner.py:955] [Warmup][Prompt][39/56] batch_size:2 seq_len:768 free_mem:34.58 GiB
INFO 06-19 08:16:10 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:10 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:11 habana_model_runner.py:955] [Warmup][Prompt][40/56] batch_size:4 seq_len:384 free_mem:34.58 GiB
INFO 06-19 08:16:11 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:11 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:11 habana_model_runner.py:955] [Warmup][Prompt][41/56] batch_size:2 seq_len:640 free_mem:34.58 GiB
INFO 06-19 08:16:11 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:11 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:12 habana_model_runner.py:955] [Warmup][Prompt][42/56] batch_size:1 seq_len:1024 free_mem:34.58 GiB
INFO 06-19 08:16:12 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:12 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:12 habana_model_runner.py:955] [Warmup][Prompt][43/56] batch_size:2 seq_len:512 free_mem:34.58 GiB
INFO 06-19 08:16:12 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:12 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:13 habana_model_runner.py:955] [Warmup][Prompt][44/56] batch_size:4 seq_len:256 free_mem:34.58 GiB
INFO 06-19 08:16:13 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:13 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:13 habana_model_runner.py:955] [Warmup][Prompt][45/56] batch_size:8 seq_len:128 free_mem:34.58 GiB
INFO 06-19 08:16:13 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:13 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:14 habana_model_runner.py:955] [Warmup][Prompt][46/56] batch_size:1 seq_len:896 free_mem:34.58 GiB
INFO 06-19 08:16:14 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:14 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:14 habana_model_runner.py:955] [Warmup][Prompt][47/56] batch_size:1 seq_len:768 free_mem:34.58 GiB
INFO 06-19 08:16:14 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:14 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:15 habana_model_runner.py:955] [Warmup][Prompt][48/56] batch_size:2 seq_len:384 free_mem:34.58 GiB
INFO 06-19 08:16:15 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:15 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:15 habana_model_runner.py:955] [Warmup][Prompt][49/56] batch_size:1 seq_len:640 free_mem:34.58 GiB
INFO 06-19 08:16:15 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:15 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:16 habana_model_runner.py:955] [Warmup][Prompt][50/56] batch_size:1 seq_len:512 free_mem:34.58 GiB
INFO 06-19 08:16:16 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:16 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:16 habana_model_runner.py:955] [Warmup][Prompt][51/56] batch_size:2 seq_len:256 free_mem:34.58 GiB
INFO 06-19 08:16:16 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:16 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:17 habana_model_runner.py:955] [Warmup][Prompt][52/56] batch_size:4 seq_len:128 free_mem:34.58 GiB
INFO 06-19 08:16:17 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:17 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:17 habana_model_runner.py:955] [Warmup][Prompt][53/56] batch_size:1 seq_len:384 free_mem:34.58 GiB
INFO 06-19 08:16:17 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:17 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:18 habana_model_runner.py:955] [Warmup][Prompt][54/56] batch_size:1 seq_len:256 free_mem:34.58 GiB
INFO 06-19 08:16:18 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:18 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:18 habana_model_runner.py:955] [Warmup][Prompt][55/56] batch_size:2 seq_len:128 free_mem:34.58 GiB
INFO 06-19 08:16:18 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:18 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:18 habana_model_runner.py:955] [Warmup][Prompt][56/56] batch_size:1 seq_len:128 free_mem:34.58 GiB
INFO 06-19 08:16:18 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:18 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:16:19 habana_model_runner.py:955] [Warmup][Decode][1/576] batch_size:256 seq_len:8192 free_mem:34.58 GiB
INFO 06-19 08:16:19 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:20 habana_model_runner.py:955] [Warmup][Decode][2/576] batch_size:256 seq_len:8064 free_mem:34.57 GiB
INFO 06-19 08:16:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:21 habana_model_runner.py:955] [Warmup][Decode][3/576] batch_size:256 seq_len:7936 free_mem:34.56 GiB
INFO 06-19 08:16:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:22 habana_model_runner.py:955] [Warmup][Decode][4/576] batch_size:256 seq_len:7808 free_mem:34.56 GiB
INFO 06-19 08:16:22 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:24 habana_model_runner.py:955] [Warmup][Decode][5/576] batch_size:256 seq_len:7680 free_mem:34.55 GiB
INFO 06-19 08:16:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:25 habana_model_runner.py:955] [Warmup][Decode][6/576] batch_size:256 seq_len:7552 free_mem:34.54 GiB
INFO 06-19 08:16:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:26 habana_model_runner.py:955] [Warmup][Decode][7/576] batch_size:256 seq_len:7424 free_mem:34.53 GiB
INFO 06-19 08:16:26 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:27 habana_model_runner.py:955] [Warmup][Decode][8/576] batch_size:256 seq_len:7296 free_mem:34.53 GiB
INFO 06-19 08:16:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:28 habana_model_runner.py:955] [Warmup][Decode][9/576] batch_size:256 seq_len:7168 free_mem:34.52 GiB
INFO 06-19 08:16:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:29 habana_model_runner.py:955] [Warmup][Decode][10/576] batch_size:256 seq_len:7040 free_mem:34.51 GiB
INFO 06-19 08:16:29 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:30 habana_model_runner.py:955] [Warmup][Decode][11/576] batch_size:256 seq_len:6912 free_mem:34.51 GiB
INFO 06-19 08:16:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:31 habana_model_runner.py:955] [Warmup][Decode][12/576] batch_size:256 seq_len:6784 free_mem:34.5 GiB
INFO 06-19 08:16:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:32 habana_model_runner.py:955] [Warmup][Decode][13/576] batch_size:256 seq_len:6656 free_mem:34.49 GiB
INFO 06-19 08:16:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:34 habana_model_runner.py:955] [Warmup][Decode][14/576] batch_size:256 seq_len:6528 free_mem:34.49 GiB
INFO 06-19 08:16:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:35 habana_model_runner.py:955] [Warmup][Decode][15/576] batch_size:256 seq_len:6400 free_mem:34.48 GiB
INFO 06-19 08:16:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:36 habana_model_runner.py:955] [Warmup][Decode][16/576] batch_size:256 seq_len:6272 free_mem:34.48 GiB
INFO 06-19 08:16:36 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:37 habana_model_runner.py:955] [Warmup][Decode][17/576] batch_size:256 seq_len:6144 free_mem:34.47 GiB
INFO 06-19 08:16:37 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:38 habana_model_runner.py:955] [Warmup][Decode][18/576] batch_size:256 seq_len:6016 free_mem:34.46 GiB
INFO 06-19 08:16:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:39 habana_model_runner.py:955] [Warmup][Decode][19/576] batch_size:256 seq_len:5888 free_mem:34.46 GiB
INFO 06-19 08:16:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:39 habana_model_runner.py:955] [Warmup][Decode][20/576] batch_size:256 seq_len:5760 free_mem:34.45 GiB
INFO 06-19 08:16:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:40 habana_model_runner.py:955] [Warmup][Decode][21/576] batch_size:256 seq_len:5632 free_mem:34.45 GiB
INFO 06-19 08:16:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:41 habana_model_runner.py:955] [Warmup][Decode][22/576] batch_size:256 seq_len:5504 free_mem:34.44 GiB
INFO 06-19 08:16:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:42 habana_model_runner.py:955] [Warmup][Decode][23/576] batch_size:256 seq_len:5376 free_mem:34.44 GiB
INFO 06-19 08:16:42 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:43 habana_model_runner.py:955] [Warmup][Decode][24/576] batch_size:256 seq_len:5248 free_mem:34.43 GiB
INFO 06-19 08:16:43 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:44 habana_model_runner.py:955] [Warmup][Decode][25/576] batch_size:256 seq_len:5120 free_mem:34.43 GiB
INFO 06-19 08:16:44 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:45 habana_model_runner.py:955] [Warmup][Decode][26/576] batch_size:256 seq_len:4992 free_mem:34.42 GiB
INFO 06-19 08:16:45 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:46 habana_model_runner.py:955] [Warmup][Decode][27/576] batch_size:256 seq_len:4864 free_mem:34.42 GiB
INFO 06-19 08:16:46 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:47 habana_model_runner.py:955] [Warmup][Decode][28/576] batch_size:256 seq_len:4736 free_mem:34.41 GiB
INFO 06-19 08:16:47 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:48 habana_model_runner.py:955] [Warmup][Decode][29/576] batch_size:256 seq_len:4608 free_mem:34.41 GiB
INFO 06-19 08:16:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:48 habana_model_runner.py:955] [Warmup][Decode][30/576] batch_size:256 seq_len:4480 free_mem:34.4 GiB
INFO 06-19 08:16:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:49 habana_model_runner.py:955] [Warmup][Decode][31/576] batch_size:256 seq_len:4352 free_mem:34.4 GiB
INFO 06-19 08:16:49 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:50 habana_model_runner.py:955] [Warmup][Decode][32/576] batch_size:256 seq_len:4224 free_mem:34.39 GiB
INFO 06-19 08:16:50 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:51 habana_model_runner.py:955] [Warmup][Decode][33/576] batch_size:128 seq_len:8192 free_mem:34.39 GiB
INFO 06-19 08:16:51 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:16:52 habana_model_runner.py:955] [Warmup][Decode][34/576] batch_size:256 seq_len:4096 free_mem:34.39 GiB
INFO 06-19 08:16:52 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:53 habana_model_runner.py:955] [Warmup][Decode][35/576] batch_size:128 seq_len:8064 free_mem:34.38 GiB
INFO 06-19 08:16:53 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:16:54 habana_model_runner.py:955] [Warmup][Decode][36/576] batch_size:128 seq_len:7936 free_mem:34.38 GiB
INFO 06-19 08:16:54 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:16:55 habana_model_runner.py:955] [Warmup][Decode][37/576] batch_size:256 seq_len:3968 free_mem:34.38 GiB
INFO 06-19 08:16:55 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:55 habana_model_runner.py:955] [Warmup][Decode][38/576] batch_size:128 seq_len:7808 free_mem:34.37 GiB
INFO 06-19 08:16:55 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:16:56 habana_model_runner.py:955] [Warmup][Decode][39/576] batch_size:128 seq_len:7680 free_mem:34.37 GiB
INFO 06-19 08:16:56 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:16:57 habana_model_runner.py:955] [Warmup][Decode][40/576] batch_size:256 seq_len:3840 free_mem:34.36 GiB
INFO 06-19 08:16:57 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:16:58 habana_model_runner.py:955] [Warmup][Decode][41/576] batch_size:128 seq_len:7552 free_mem:34.36 GiB
INFO 06-19 08:16:58 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:16:59 habana_model_runner.py:955] [Warmup][Decode][42/576] batch_size:128 seq_len:7424 free_mem:34.36 GiB
INFO 06-19 08:16:59 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:00 habana_model_runner.py:955] [Warmup][Decode][43/576] batch_size:256 seq_len:3712 free_mem:34.35 GiB
INFO 06-19 08:17:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:00 habana_model_runner.py:955] [Warmup][Decode][44/576] batch_size:128 seq_len:7296 free_mem:34.35 GiB
INFO 06-19 08:17:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:01 habana_model_runner.py:955] [Warmup][Decode][45/576] batch_size:128 seq_len:7168 free_mem:34.35 GiB
INFO 06-19 08:17:01 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:02 habana_model_runner.py:955] [Warmup][Decode][46/576] batch_size:256 seq_len:3584 free_mem:34.34 GiB
INFO 06-19 08:17:02 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:03 habana_model_runner.py:955] [Warmup][Decode][47/576] batch_size:128 seq_len:7040 free_mem:34.34 GiB
INFO 06-19 08:17:03 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:04 habana_model_runner.py:955] [Warmup][Decode][48/576] batch_size:128 seq_len:6912 free_mem:34.34 GiB
INFO 06-19 08:17:04 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:05 habana_model_runner.py:955] [Warmup][Decode][49/576] batch_size:256 seq_len:3456 free_mem:34.33 GiB
INFO 06-19 08:17:05 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:05 habana_model_runner.py:955] [Warmup][Decode][50/576] batch_size:128 seq_len:6784 free_mem:34.33 GiB
INFO 06-19 08:17:05 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:06 habana_model_runner.py:955] [Warmup][Decode][51/576] batch_size:128 seq_len:6656 free_mem:34.33 GiB
INFO 06-19 08:17:06 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:07 habana_model_runner.py:955] [Warmup][Decode][52/576] batch_size:256 seq_len:3328 free_mem:34.32 GiB
INFO 06-19 08:17:07 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:08 habana_model_runner.py:955] [Warmup][Decode][53/576] batch_size:128 seq_len:6528 free_mem:34.32 GiB
INFO 06-19 08:17:08 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:09 habana_model_runner.py:955] [Warmup][Decode][54/576] batch_size:128 seq_len:6400 free_mem:34.32 GiB
INFO 06-19 08:17:09 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:09 habana_model_runner.py:955] [Warmup][Decode][55/576] batch_size:256 seq_len:3200 free_mem:34.31 GiB
INFO 06-19 08:17:09 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:10 habana_model_runner.py:955] [Warmup][Decode][56/576] batch_size:128 seq_len:6272 free_mem:34.31 GiB
INFO 06-19 08:17:10 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:11 habana_model_runner.py:955] [Warmup][Decode][57/576] batch_size:128 seq_len:6144 free_mem:34.31 GiB
INFO 06-19 08:17:11 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:12 habana_model_runner.py:955] [Warmup][Decode][58/576] batch_size:256 seq_len:3072 free_mem:34.3 GiB
INFO 06-19 08:17:12 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:12 habana_model_runner.py:955] [Warmup][Decode][59/576] batch_size:128 seq_len:6016 free_mem:34.3 GiB
INFO 06-19 08:17:12 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:13 habana_model_runner.py:955] [Warmup][Decode][60/576] batch_size:128 seq_len:5888 free_mem:34.3 GiB
INFO 06-19 08:17:13 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:14 habana_model_runner.py:955] [Warmup][Decode][61/576] batch_size:256 seq_len:2944 free_mem:34.3 GiB
INFO 06-19 08:17:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:15 habana_model_runner.py:955] [Warmup][Decode][62/576] batch_size:128 seq_len:5760 free_mem:34.29 GiB
INFO 06-19 08:17:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:15 habana_model_runner.py:955] [Warmup][Decode][63/576] batch_size:128 seq_len:5632 free_mem:34.29 GiB
INFO 06-19 08:17:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:16 habana_model_runner.py:955] [Warmup][Decode][64/576] batch_size:256 seq_len:2816 free_mem:34.29 GiB
INFO 06-19 08:17:16 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:17 habana_model_runner.py:955] [Warmup][Decode][65/576] batch_size:128 seq_len:5504 free_mem:34.28 GiB
INFO 06-19 08:17:17 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:18 habana_model_runner.py:955] [Warmup][Decode][66/576] batch_size:128 seq_len:5376 free_mem:34.28 GiB
INFO 06-19 08:17:18 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:18 habana_model_runner.py:955] [Warmup][Decode][67/576] batch_size:256 seq_len:2688 free_mem:34.28 GiB
INFO 06-19 08:17:18 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:19 habana_model_runner.py:955] [Warmup][Decode][68/576] batch_size:128 seq_len:5248 free_mem:34.28 GiB
INFO 06-19 08:17:19 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:20 habana_model_runner.py:955] [Warmup][Decode][69/576] batch_size:128 seq_len:5120 free_mem:34.27 GiB
INFO 06-19 08:17:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:20 habana_model_runner.py:955] [Warmup][Decode][70/576] batch_size:256 seq_len:2560 free_mem:34.27 GiB
INFO 06-19 08:17:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:21 habana_model_runner.py:955] [Warmup][Decode][71/576] batch_size:128 seq_len:4992 free_mem:34.27 GiB
INFO 06-19 08:17:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:22 habana_model_runner.py:955] [Warmup][Decode][72/576] batch_size:128 seq_len:4864 free_mem:34.27 GiB
INFO 06-19 08:17:22 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:22 habana_model_runner.py:955] [Warmup][Decode][73/576] batch_size:256 seq_len:2432 free_mem:34.27 GiB
INFO 06-19 08:17:22 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:23 habana_model_runner.py:955] [Warmup][Decode][74/576] batch_size:128 seq_len:4736 free_mem:34.26 GiB
INFO 06-19 08:17:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:24 habana_model_runner.py:955] [Warmup][Decode][75/576] batch_size:128 seq_len:4608 free_mem:34.26 GiB
INFO 06-19 08:17:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:24 habana_model_runner.py:955] [Warmup][Decode][76/576] batch_size:256 seq_len:2304 free_mem:34.26 GiB
INFO 06-19 08:17:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:25 habana_model_runner.py:955] [Warmup][Decode][77/576] batch_size:128 seq_len:4480 free_mem:34.26 GiB
INFO 06-19 08:17:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:26 habana_model_runner.py:955] [Warmup][Decode][78/576] batch_size:128 seq_len:4352 free_mem:34.25 GiB
INFO 06-19 08:17:26 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:26 habana_model_runner.py:955] [Warmup][Decode][79/576] batch_size:256 seq_len:2176 free_mem:34.25 GiB
INFO 06-19 08:17:26 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:27 habana_model_runner.py:955] [Warmup][Decode][80/576] batch_size:128 seq_len:4224 free_mem:34.25 GiB
INFO 06-19 08:17:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:28 habana_model_runner.py:955] [Warmup][Decode][81/576] batch_size:64 seq_len:8192 free_mem:34.25 GiB
INFO 06-19 08:17:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:28 habana_model_runner.py:955] [Warmup][Decode][82/576] batch_size:128 seq_len:4096 free_mem:34.25 GiB
INFO 06-19 08:17:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:29 habana_model_runner.py:955] [Warmup][Decode][83/576] batch_size:256 seq_len:2048 free_mem:34.24 GiB
INFO 06-19 08:17:29 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:30 habana_model_runner.py:955] [Warmup][Decode][84/576] batch_size:64 seq_len:8064 free_mem:34.24 GiB
INFO 06-19 08:17:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:30 habana_model_runner.py:955] [Warmup][Decode][85/576] batch_size:64 seq_len:7936 free_mem:34.24 GiB
INFO 06-19 08:17:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:31 habana_model_runner.py:955] [Warmup][Decode][86/576] batch_size:128 seq_len:3968 free_mem:34.24 GiB
INFO 06-19 08:17:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:32 habana_model_runner.py:955] [Warmup][Decode][87/576] batch_size:64 seq_len:7808 free_mem:34.24 GiB
INFO 06-19 08:17:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:33 habana_model_runner.py:955] [Warmup][Decode][88/576] batch_size:64 seq_len:7680 free_mem:34.23 GiB
INFO 06-19 08:17:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:34 habana_model_runner.py:955] [Warmup][Decode][89/576] batch_size:128 seq_len:3840 free_mem:34.23 GiB
INFO 06-19 08:17:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:34 habana_model_runner.py:955] [Warmup][Decode][90/576] batch_size:256 seq_len:1920 free_mem:34.23 GiB
INFO 06-19 08:17:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:35 habana_model_runner.py:955] [Warmup][Decode][91/576] batch_size:64 seq_len:7552 free_mem:34.23 GiB
INFO 06-19 08:17:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:36 habana_model_runner.py:955] [Warmup][Decode][92/576] batch_size:64 seq_len:7424 free_mem:34.23 GiB
INFO 06-19 08:17:36 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:36 habana_model_runner.py:955] [Warmup][Decode][93/576] batch_size:128 seq_len:3712 free_mem:34.23 GiB
INFO 06-19 08:17:36 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:37 habana_model_runner.py:955] [Warmup][Decode][94/576] batch_size:64 seq_len:7296 free_mem:34.22 GiB
INFO 06-19 08:17:37 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:38 habana_model_runner.py:955] [Warmup][Decode][95/576] batch_size:64 seq_len:7168 free_mem:34.22 GiB
INFO 06-19 08:17:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:39 habana_model_runner.py:955] [Warmup][Decode][96/576] batch_size:128 seq_len:3584 free_mem:34.22 GiB
INFO 06-19 08:17:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:39 habana_model_runner.py:955] [Warmup][Decode][97/576] batch_size:256 seq_len:1792 free_mem:34.22 GiB
INFO 06-19 08:17:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:40 habana_model_runner.py:955] [Warmup][Decode][98/576] batch_size:64 seq_len:7040 free_mem:34.22 GiB
INFO 06-19 08:17:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:41 habana_model_runner.py:955] [Warmup][Decode][99/576] batch_size:64 seq_len:6912 free_mem:34.21 GiB
INFO 06-19 08:17:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:41 habana_model_runner.py:955] [Warmup][Decode][100/576] batch_size:128 seq_len:3456 free_mem:34.21 GiB
INFO 06-19 08:17:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:42 habana_model_runner.py:955] [Warmup][Decode][101/576] batch_size:64 seq_len:6784 free_mem:34.21 GiB
INFO 06-19 08:17:42 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:43 habana_model_runner.py:955] [Warmup][Decode][102/576] batch_size:64 seq_len:6656 free_mem:34.21 GiB
INFO 06-19 08:17:43 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:43 habana_model_runner.py:955] [Warmup][Decode][103/576] batch_size:128 seq_len:3328 free_mem:34.21 GiB
INFO 06-19 08:17:43 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:44 habana_model_runner.py:955] [Warmup][Decode][104/576] batch_size:256 seq_len:1664 free_mem:34.21 GiB
INFO 06-19 08:17:44 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:44 habana_model_runner.py:955] [Warmup][Decode][105/576] batch_size:64 seq_len:6528 free_mem:34.21 GiB
INFO 06-19 08:17:44 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:45 habana_model_runner.py:955] [Warmup][Decode][106/576] batch_size:64 seq_len:6400 free_mem:34.2 GiB
INFO 06-19 08:17:45 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:46 habana_model_runner.py:955] [Warmup][Decode][107/576] batch_size:128 seq_len:3200 free_mem:34.2 GiB
INFO 06-19 08:17:46 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:47 habana_model_runner.py:955] [Warmup][Decode][108/576] batch_size:64 seq_len:6272 free_mem:34.2 GiB
INFO 06-19 08:17:47 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:47 habana_model_runner.py:955] [Warmup][Decode][109/576] batch_size:64 seq_len:6144 free_mem:34.2 GiB
INFO 06-19 08:17:47 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:48 habana_model_runner.py:955] [Warmup][Decode][110/576] batch_size:128 seq_len:3072 free_mem:34.2 GiB
INFO 06-19 08:17:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:49 habana_model_runner.py:955] [Warmup][Decode][111/576] batch_size:256 seq_len:1536 free_mem:34.2 GiB
INFO 06-19 08:17:49 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:49 habana_model_runner.py:955] [Warmup][Decode][112/576] batch_size:64 seq_len:6016 free_mem:34.19 GiB
INFO 06-19 08:17:49 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:50 habana_model_runner.py:955] [Warmup][Decode][113/576] batch_size:64 seq_len:5888 free_mem:34.19 GiB
INFO 06-19 08:17:50 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:51 habana_model_runner.py:955] [Warmup][Decode][114/576] batch_size:128 seq_len:2944 free_mem:34.19 GiB
INFO 06-19 08:17:51 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:51 habana_model_runner.py:955] [Warmup][Decode][115/576] batch_size:64 seq_len:5760 free_mem:34.19 GiB
INFO 06-19 08:17:51 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:52 habana_model_runner.py:955] [Warmup][Decode][116/576] batch_size:64 seq_len:5632 free_mem:34.19 GiB
INFO 06-19 08:17:52 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:53 habana_model_runner.py:955] [Warmup][Decode][117/576] batch_size:128 seq_len:2816 free_mem:34.19 GiB
INFO 06-19 08:17:53 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:53 habana_model_runner.py:955] [Warmup][Decode][118/576] batch_size:256 seq_len:1408 free_mem:34.19 GiB
INFO 06-19 08:17:53 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:54 habana_model_runner.py:955] [Warmup][Decode][119/576] batch_size:64 seq_len:5504 free_mem:34.19 GiB
INFO 06-19 08:17:54 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:55 habana_model_runner.py:955] [Warmup][Decode][120/576] batch_size:64 seq_len:5376 free_mem:34.18 GiB
INFO 06-19 08:17:55 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:55 habana_model_runner.py:955] [Warmup][Decode][121/576] batch_size:128 seq_len:2688 free_mem:34.18 GiB
INFO 06-19 08:17:55 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:56 habana_model_runner.py:955] [Warmup][Decode][122/576] batch_size:64 seq_len:5248 free_mem:34.18 GiB
INFO 06-19 08:17:56 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:57 habana_model_runner.py:955] [Warmup][Decode][123/576] batch_size:64 seq_len:5120 free_mem:34.18 GiB
INFO 06-19 08:17:57 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:57 habana_model_runner.py:955] [Warmup][Decode][124/576] batch_size:128 seq_len:2560 free_mem:34.18 GiB
INFO 06-19 08:17:57 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:17:58 habana_model_runner.py:955] [Warmup][Decode][125/576] batch_size:256 seq_len:1280 free_mem:34.18 GiB
INFO 06-19 08:17:58 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:17:58 habana_model_runner.py:955] [Warmup][Decode][126/576] batch_size:64 seq_len:4992 free_mem:34.18 GiB
INFO 06-19 08:17:58 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:17:59 habana_model_runner.py:955] [Warmup][Decode][127/576] batch_size:64 seq_len:4864 free_mem:34.18 GiB
INFO 06-19 08:17:59 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:00 habana_model_runner.py:955] [Warmup][Decode][128/576] batch_size:128 seq_len:2432 free_mem:34.17 GiB
INFO 06-19 08:18:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:00 habana_model_runner.py:955] [Warmup][Decode][129/576] batch_size:64 seq_len:4736 free_mem:34.17 GiB
INFO 06-19 08:18:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:01 habana_model_runner.py:955] [Warmup][Decode][130/576] batch_size:64 seq_len:4608 free_mem:34.17 GiB
INFO 06-19 08:18:01 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:01 habana_model_runner.py:955] [Warmup][Decode][131/576] batch_size:128 seq_len:2304 free_mem:34.17 GiB
INFO 06-19 08:18:01 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:02 habana_model_runner.py:955] [Warmup][Decode][132/576] batch_size:256 seq_len:1152 free_mem:34.17 GiB
INFO 06-19 08:18:02 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:18:03 habana_model_runner.py:955] [Warmup][Decode][133/576] batch_size:64 seq_len:4480 free_mem:34.17 GiB
INFO 06-19 08:18:03 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:03 habana_model_runner.py:955] [Warmup][Decode][134/576] batch_size:64 seq_len:4352 free_mem:34.17 GiB
INFO 06-19 08:18:03 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:04 habana_model_runner.py:955] [Warmup][Decode][135/576] batch_size:128 seq_len:2176 free_mem:34.17 GiB
INFO 06-19 08:18:04 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:04 habana_model_runner.py:955] [Warmup][Decode][136/576] batch_size:64 seq_len:4224 free_mem:34.17 GiB
INFO 06-19 08:18:04 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:05 habana_model_runner.py:955] [Warmup][Decode][137/576] batch_size:32 seq_len:8192 free_mem:34.16 GiB
INFO 06-19 08:18:05 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:06 habana_model_runner.py:955] [Warmup][Decode][138/576] batch_size:64 seq_len:4096 free_mem:34.16 GiB
INFO 06-19 08:18:06 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:06 habana_model_runner.py:955] [Warmup][Decode][139/576] batch_size:128 seq_len:2048 free_mem:34.16 GiB
INFO 06-19 08:18:06 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:07 habana_model_runner.py:955] [Warmup][Decode][140/576] batch_size:256 seq_len:1024 free_mem:34.16 GiB
INFO 06-19 08:18:07 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:18:07 habana_model_runner.py:955] [Warmup][Decode][141/576] batch_size:32 seq_len:8064 free_mem:34.16 GiB
INFO 06-19 08:18:07 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:08 habana_model_runner.py:955] [Warmup][Decode][142/576] batch_size:32 seq_len:7936 free_mem:34.16 GiB
INFO 06-19 08:18:08 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:09 habana_model_runner.py:955] [Warmup][Decode][143/576] batch_size:64 seq_len:3968 free_mem:34.16 GiB
INFO 06-19 08:18:09 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:09 habana_model_runner.py:955] [Warmup][Decode][144/576] batch_size:32 seq_len:7808 free_mem:34.16 GiB
INFO 06-19 08:18:09 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:10 habana_model_runner.py:955] [Warmup][Decode][145/576] batch_size:32 seq_len:7680 free_mem:34.16 GiB
INFO 06-19 08:18:10 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:11 habana_model_runner.py:955] [Warmup][Decode][146/576] batch_size:64 seq_len:3840 free_mem:34.16 GiB
INFO 06-19 08:18:11 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:11 habana_model_runner.py:955] [Warmup][Decode][147/576] batch_size:128 seq_len:1920 free_mem:34.16 GiB
INFO 06-19 08:18:11 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:12 habana_model_runner.py:955] [Warmup][Decode][148/576] batch_size:32 seq_len:7552 free_mem:34.16 GiB
INFO 06-19 08:18:12 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:13 habana_model_runner.py:955] [Warmup][Decode][149/576] batch_size:32 seq_len:7424 free_mem:34.16 GiB
INFO 06-19 08:18:13 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:13 habana_model_runner.py:955] [Warmup][Decode][150/576] batch_size:64 seq_len:3712 free_mem:34.16 GiB
INFO 06-19 08:18:13 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:14 habana_model_runner.py:955] [Warmup][Decode][151/576] batch_size:32 seq_len:7296 free_mem:34.16 GiB
INFO 06-19 08:18:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:14 habana_model_runner.py:955] [Warmup][Decode][152/576] batch_size:32 seq_len:7168 free_mem:34.16 GiB
INFO 06-19 08:18:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:15 habana_model_runner.py:955] [Warmup][Decode][153/576] batch_size:64 seq_len:3584 free_mem:34.16 GiB
INFO 06-19 08:18:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:16 habana_model_runner.py:955] [Warmup][Decode][154/576] batch_size:128 seq_len:1792 free_mem:34.16 GiB
INFO 06-19 08:18:16 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:16 habana_model_runner.py:955] [Warmup][Decode][155/576] batch_size:256 seq_len:896 free_mem:34.16 GiB
INFO 06-19 08:18:16 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:18:17 habana_model_runner.py:955] [Warmup][Decode][156/576] batch_size:32 seq_len:7040 free_mem:34.16 GiB
INFO 06-19 08:18:17 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:17 habana_model_runner.py:955] [Warmup][Decode][157/576] batch_size:32 seq_len:6912 free_mem:34.16 GiB
INFO 06-19 08:18:17 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:18 habana_model_runner.py:955] [Warmup][Decode][158/576] batch_size:64 seq_len:3456 free_mem:34.16 GiB
INFO 06-19 08:18:18 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:18 habana_model_runner.py:955] [Warmup][Decode][159/576] batch_size:32 seq_len:6784 free_mem:34.16 GiB
INFO 06-19 08:18:18 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:19 habana_model_runner.py:955] [Warmup][Decode][160/576] batch_size:32 seq_len:6656 free_mem:34.16 GiB
INFO 06-19 08:18:19 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:20 habana_model_runner.py:955] [Warmup][Decode][161/576] batch_size:64 seq_len:3328 free_mem:34.16 GiB
INFO 06-19 08:18:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:20 habana_model_runner.py:955] [Warmup][Decode][162/576] batch_size:128 seq_len:1664 free_mem:34.16 GiB
INFO 06-19 08:18:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:21 habana_model_runner.py:955] [Warmup][Decode][163/576] batch_size:32 seq_len:6528 free_mem:34.16 GiB
INFO 06-19 08:18:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:21 habana_model_runner.py:955] [Warmup][Decode][164/576] batch_size:32 seq_len:6400 free_mem:34.16 GiB
INFO 06-19 08:18:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:22 habana_model_runner.py:955] [Warmup][Decode][165/576] batch_size:64 seq_len:3200 free_mem:34.16 GiB
INFO 06-19 08:18:22 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:23 habana_model_runner.py:955] [Warmup][Decode][166/576] batch_size:32 seq_len:6272 free_mem:34.16 GiB
INFO 06-19 08:18:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:23 habana_model_runner.py:955] [Warmup][Decode][167/576] batch_size:32 seq_len:6144 free_mem:34.16 GiB
INFO 06-19 08:18:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:24 habana_model_runner.py:955] [Warmup][Decode][168/576] batch_size:64 seq_len:3072 free_mem:34.16 GiB
INFO 06-19 08:18:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:24 habana_model_runner.py:955] [Warmup][Decode][169/576] batch_size:128 seq_len:1536 free_mem:34.16 GiB
INFO 06-19 08:18:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:25 habana_model_runner.py:955] [Warmup][Decode][170/576] batch_size:256 seq_len:768 free_mem:34.16 GiB
INFO 06-19 08:18:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:18:25 habana_model_runner.py:955] [Warmup][Decode][171/576] batch_size:32 seq_len:6016 free_mem:34.16 GiB
INFO 06-19 08:18:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:26 habana_model_runner.py:955] [Warmup][Decode][172/576] batch_size:32 seq_len:5888 free_mem:34.16 GiB
INFO 06-19 08:18:26 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:27 habana_model_runner.py:955] [Warmup][Decode][173/576] batch_size:64 seq_len:2944 free_mem:34.16 GiB
INFO 06-19 08:18:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:27 habana_model_runner.py:955] [Warmup][Decode][174/576] batch_size:32 seq_len:5760 free_mem:34.16 GiB
INFO 06-19 08:18:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:28 habana_model_runner.py:955] [Warmup][Decode][175/576] batch_size:32 seq_len:5632 free_mem:34.16 GiB
INFO 06-19 08:18:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:28 habana_model_runner.py:955] [Warmup][Decode][176/576] batch_size:64 seq_len:2816 free_mem:34.16 GiB
INFO 06-19 08:18:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:29 habana_model_runner.py:955] [Warmup][Decode][177/576] batch_size:128 seq_len:1408 free_mem:34.16 GiB
INFO 06-19 08:18:29 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:30 habana_model_runner.py:955] [Warmup][Decode][178/576] batch_size:32 seq_len:5504 free_mem:34.16 GiB
INFO 06-19 08:18:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:30 habana_model_runner.py:955] [Warmup][Decode][179/576] batch_size:32 seq_len:5376 free_mem:34.16 GiB
INFO 06-19 08:18:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:31 habana_model_runner.py:955] [Warmup][Decode][180/576] batch_size:64 seq_len:2688 free_mem:34.16 GiB
INFO 06-19 08:18:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:31 habana_model_runner.py:955] [Warmup][Decode][181/576] batch_size:32 seq_len:5248 free_mem:34.16 GiB
INFO 06-19 08:18:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:32 habana_model_runner.py:955] [Warmup][Decode][182/576] batch_size:32 seq_len:5120 free_mem:34.16 GiB
INFO 06-19 08:18:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:32 habana_model_runner.py:955] [Warmup][Decode][183/576] batch_size:64 seq_len:2560 free_mem:34.16 GiB
INFO 06-19 08:18:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:33 habana_model_runner.py:955] [Warmup][Decode][184/576] batch_size:128 seq_len:1280 free_mem:34.16 GiB
INFO 06-19 08:18:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:33 habana_model_runner.py:955] [Warmup][Decode][185/576] batch_size:256 seq_len:640 free_mem:34.16 GiB
INFO 06-19 08:18:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:18:34 habana_model_runner.py:955] [Warmup][Decode][186/576] batch_size:32 seq_len:4992 free_mem:34.16 GiB
INFO 06-19 08:18:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:34 habana_model_runner.py:955] [Warmup][Decode][187/576] batch_size:32 seq_len:4864 free_mem:34.16 GiB
INFO 06-19 08:18:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:35 habana_model_runner.py:955] [Warmup][Decode][188/576] batch_size:64 seq_len:2432 free_mem:34.16 GiB
INFO 06-19 08:18:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:35 habana_model_runner.py:955] [Warmup][Decode][189/576] batch_size:32 seq_len:4736 free_mem:34.16 GiB
INFO 06-19 08:18:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:36 habana_model_runner.py:955] [Warmup][Decode][190/576] batch_size:32 seq_len:4608 free_mem:34.16 GiB
INFO 06-19 08:18:36 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:37 habana_model_runner.py:955] [Warmup][Decode][191/576] batch_size:64 seq_len:2304 free_mem:34.16 GiB
INFO 06-19 08:18:37 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:37 habana_model_runner.py:955] [Warmup][Decode][192/576] batch_size:128 seq_len:1152 free_mem:34.16 GiB
INFO 06-19 08:18:37 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:38 habana_model_runner.py:955] [Warmup][Decode][193/576] batch_size:32 seq_len:4480 free_mem:34.16 GiB
INFO 06-19 08:18:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:38 habana_model_runner.py:955] [Warmup][Decode][194/576] batch_size:32 seq_len:4352 free_mem:34.16 GiB
INFO 06-19 08:18:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:39 habana_model_runner.py:955] [Warmup][Decode][195/576] batch_size:64 seq_len:2176 free_mem:34.16 GiB
INFO 06-19 08:18:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:39 habana_model_runner.py:955] [Warmup][Decode][196/576] batch_size:32 seq_len:4224 free_mem:34.16 GiB
INFO 06-19 08:18:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:40 habana_model_runner.py:955] [Warmup][Decode][197/576] batch_size:16 seq_len:8192 free_mem:34.16 GiB
INFO 06-19 08:18:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:41 habana_model_runner.py:955] [Warmup][Decode][198/576] batch_size:32 seq_len:4096 free_mem:34.16 GiB
INFO 06-19 08:18:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:41 habana_model_runner.py:955] [Warmup][Decode][199/576] batch_size:64 seq_len:2048 free_mem:34.16 GiB
INFO 06-19 08:18:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:41 habana_model_runner.py:955] [Warmup][Decode][200/576] batch_size:128 seq_len:1024 free_mem:34.16 GiB
INFO 06-19 08:18:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:42 habana_model_runner.py:955] [Warmup][Decode][201/576] batch_size:256 seq_len:512 free_mem:34.16 GiB
INFO 06-19 08:18:42 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:18:42 habana_model_runner.py:955] [Warmup][Decode][202/576] batch_size:16 seq_len:8064 free_mem:34.16 GiB
INFO 06-19 08:18:42 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:43 habana_model_runner.py:955] [Warmup][Decode][203/576] batch_size:16 seq_len:7936 free_mem:34.16 GiB
INFO 06-19 08:18:43 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:44 habana_model_runner.py:955] [Warmup][Decode][204/576] batch_size:32 seq_len:3968 free_mem:34.16 GiB
INFO 06-19 08:18:44 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:44 habana_model_runner.py:955] [Warmup][Decode][205/576] batch_size:16 seq_len:7808 free_mem:34.16 GiB
INFO 06-19 08:18:44 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:45 habana_model_runner.py:955] [Warmup][Decode][206/576] batch_size:16 seq_len:7680 free_mem:34.16 GiB
INFO 06-19 08:18:45 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:45 habana_model_runner.py:955] [Warmup][Decode][207/576] batch_size:32 seq_len:3840 free_mem:34.16 GiB
INFO 06-19 08:18:45 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:46 habana_model_runner.py:955] [Warmup][Decode][208/576] batch_size:64 seq_len:1920 free_mem:34.16 GiB
INFO 06-19 08:18:46 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:46 habana_model_runner.py:955] [Warmup][Decode][209/576] batch_size:16 seq_len:7552 free_mem:34.16 GiB
INFO 06-19 08:18:46 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:47 habana_model_runner.py:955] [Warmup][Decode][210/576] batch_size:16 seq_len:7424 free_mem:34.16 GiB
INFO 06-19 08:18:47 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:48 habana_model_runner.py:955] [Warmup][Decode][211/576] batch_size:32 seq_len:3712 free_mem:34.16 GiB
INFO 06-19 08:18:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:48 habana_model_runner.py:955] [Warmup][Decode][212/576] batch_size:16 seq_len:7296 free_mem:34.16 GiB
INFO 06-19 08:18:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:49 habana_model_runner.py:955] [Warmup][Decode][213/576] batch_size:16 seq_len:7168 free_mem:34.16 GiB
INFO 06-19 08:18:49 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:49 habana_model_runner.py:955] [Warmup][Decode][214/576] batch_size:32 seq_len:3584 free_mem:34.16 GiB
INFO 06-19 08:18:49 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:50 habana_model_runner.py:955] [Warmup][Decode][215/576] batch_size:64 seq_len:1792 free_mem:34.16 GiB
INFO 06-19 08:18:50 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:50 habana_model_runner.py:955] [Warmup][Decode][216/576] batch_size:128 seq_len:896 free_mem:34.16 GiB
INFO 06-19 08:18:50 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:51 habana_model_runner.py:955] [Warmup][Decode][217/576] batch_size:16 seq_len:7040 free_mem:34.16 GiB
INFO 06-19 08:18:51 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:51 habana_model_runner.py:955] [Warmup][Decode][218/576] batch_size:16 seq_len:6912 free_mem:34.16 GiB
INFO 06-19 08:18:51 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:52 habana_model_runner.py:955] [Warmup][Decode][219/576] batch_size:32 seq_len:3456 free_mem:34.16 GiB
INFO 06-19 08:18:52 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:52 habana_model_runner.py:955] [Warmup][Decode][220/576] batch_size:16 seq_len:6784 free_mem:34.16 GiB
INFO 06-19 08:18:52 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:53 habana_model_runner.py:955] [Warmup][Decode][221/576] batch_size:16 seq_len:6656 free_mem:34.16 GiB
INFO 06-19 08:18:53 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:54 habana_model_runner.py:955] [Warmup][Decode][222/576] batch_size:32 seq_len:3328 free_mem:34.16 GiB
INFO 06-19 08:18:54 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:54 habana_model_runner.py:955] [Warmup][Decode][223/576] batch_size:64 seq_len:1664 free_mem:34.16 GiB
INFO 06-19 08:18:54 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:54 habana_model_runner.py:955] [Warmup][Decode][224/576] batch_size:16 seq_len:6528 free_mem:34.16 GiB
INFO 06-19 08:18:55 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:55 habana_model_runner.py:955] [Warmup][Decode][225/576] batch_size:16 seq_len:6400 free_mem:34.16 GiB
INFO 06-19 08:18:55 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:56 habana_model_runner.py:955] [Warmup][Decode][226/576] batch_size:32 seq_len:3200 free_mem:34.16 GiB
INFO 06-19 08:18:56 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:56 habana_model_runner.py:955] [Warmup][Decode][227/576] batch_size:16 seq_len:6272 free_mem:34.16 GiB
INFO 06-19 08:18:56 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:57 habana_model_runner.py:955] [Warmup][Decode][228/576] batch_size:16 seq_len:6144 free_mem:34.16 GiB
INFO 06-19 08:18:57 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:18:57 habana_model_runner.py:955] [Warmup][Decode][229/576] batch_size:32 seq_len:3072 free_mem:34.16 GiB
INFO 06-19 08:18:57 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:18:58 habana_model_runner.py:955] [Warmup][Decode][230/576] batch_size:64 seq_len:1536 free_mem:34.16 GiB
INFO 06-19 08:18:58 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:18:58 habana_model_runner.py:955] [Warmup][Decode][231/576] batch_size:128 seq_len:768 free_mem:34.16 GiB
INFO 06-19 08:18:58 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:18:59 habana_model_runner.py:955] [Warmup][Decode][232/576] batch_size:256 seq_len:384 free_mem:34.16 GiB
INFO 06-19 08:18:59 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:18:59 habana_model_runner.py:955] [Warmup][Decode][233/576] batch_size:16 seq_len:6016 free_mem:34.16 GiB
INFO 06-19 08:18:59 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:00 habana_model_runner.py:955] [Warmup][Decode][234/576] batch_size:16 seq_len:5888 free_mem:34.16 GiB
INFO 06-19 08:19:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:00 habana_model_runner.py:955] [Warmup][Decode][235/576] batch_size:32 seq_len:2944 free_mem:34.16 GiB
INFO 06-19 08:19:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:01 habana_model_runner.py:955] [Warmup][Decode][236/576] batch_size:16 seq_len:5760 free_mem:34.16 GiB
INFO 06-19 08:19:01 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:01 habana_model_runner.py:955] [Warmup][Decode][237/576] batch_size:16 seq_len:5632 free_mem:34.16 GiB
INFO 06-19 08:19:01 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:02 habana_model_runner.py:955] [Warmup][Decode][238/576] batch_size:32 seq_len:2816 free_mem:34.16 GiB
INFO 06-19 08:19:02 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:02 habana_model_runner.py:955] [Warmup][Decode][239/576] batch_size:64 seq_len:1408 free_mem:34.16 GiB
INFO 06-19 08:19:02 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:19:03 habana_model_runner.py:955] [Warmup][Decode][240/576] batch_size:16 seq_len:5504 free_mem:34.16 GiB
INFO 06-19 08:19:03 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:04 habana_model_runner.py:955] [Warmup][Decode][241/576] batch_size:16 seq_len:5376 free_mem:34.16 GiB
INFO 06-19 08:19:04 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:04 habana_model_runner.py:955] [Warmup][Decode][242/576] batch_size:32 seq_len:2688 free_mem:34.16 GiB
INFO 06-19 08:19:04 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:05 habana_model_runner.py:955] [Warmup][Decode][243/576] batch_size:16 seq_len:5248 free_mem:34.16 GiB
INFO 06-19 08:19:05 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:05 habana_model_runner.py:955] [Warmup][Decode][244/576] batch_size:16 seq_len:5120 free_mem:34.16 GiB
INFO 06-19 08:19:05 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:06 habana_model_runner.py:955] [Warmup][Decode][245/576] batch_size:32 seq_len:2560 free_mem:34.16 GiB
INFO 06-19 08:19:06 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:06 habana_model_runner.py:955] [Warmup][Decode][246/576] batch_size:64 seq_len:1280 free_mem:34.16 GiB
INFO 06-19 08:19:06 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:19:07 habana_model_runner.py:955] [Warmup][Decode][247/576] batch_size:128 seq_len:640 free_mem:34.16 GiB
INFO 06-19 08:19:07 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:19:07 habana_model_runner.py:955] [Warmup][Decode][248/576] batch_size:16 seq_len:4992 free_mem:34.16 GiB
INFO 06-19 08:19:07 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:08 habana_model_runner.py:955] [Warmup][Decode][249/576] batch_size:16 seq_len:4864 free_mem:34.16 GiB
INFO 06-19 08:19:08 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:08 habana_model_runner.py:955] [Warmup][Decode][250/576] batch_size:32 seq_len:2432 free_mem:34.16 GiB
INFO 06-19 08:19:08 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:09 habana_model_runner.py:955] [Warmup][Decode][251/576] batch_size:16 seq_len:4736 free_mem:34.16 GiB
INFO 06-19 08:19:09 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:09 habana_model_runner.py:955] [Warmup][Decode][252/576] batch_size:16 seq_len:4608 free_mem:34.16 GiB
INFO 06-19 08:19:09 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:10 habana_model_runner.py:955] [Warmup][Decode][253/576] batch_size:32 seq_len:2304 free_mem:34.16 GiB
INFO 06-19 08:19:10 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:10 habana_model_runner.py:955] [Warmup][Decode][254/576] batch_size:64 seq_len:1152 free_mem:34.16 GiB
INFO 06-19 08:19:10 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:19:11 habana_model_runner.py:955] [Warmup][Decode][255/576] batch_size:16 seq_len:4480 free_mem:34.16 GiB
INFO 06-19 08:19:11 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:11 habana_model_runner.py:955] [Warmup][Decode][256/576] batch_size:16 seq_len:4352 free_mem:34.16 GiB
INFO 06-19 08:19:11 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:12 habana_model_runner.py:955] [Warmup][Decode][257/576] batch_size:32 seq_len:2176 free_mem:34.16 GiB
INFO 06-19 08:19:12 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:12 habana_model_runner.py:955] [Warmup][Decode][258/576] batch_size:16 seq_len:4224 free_mem:34.16 GiB
INFO 06-19 08:19:12 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:13 habana_model_runner.py:955] [Warmup][Decode][259/576] batch_size:8 seq_len:8192 free_mem:34.16 GiB
INFO 06-19 08:19:13 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:14 habana_model_runner.py:955] [Warmup][Decode][260/576] batch_size:16 seq_len:4096 free_mem:34.16 GiB
INFO 06-19 08:19:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:14 habana_model_runner.py:955] [Warmup][Decode][261/576] batch_size:32 seq_len:2048 free_mem:34.16 GiB
INFO 06-19 08:19:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:14 habana_model_runner.py:955] [Warmup][Decode][262/576] batch_size:64 seq_len:1024 free_mem:34.16 GiB
INFO 06-19 08:19:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:19:15 habana_model_runner.py:955] [Warmup][Decode][263/576] batch_size:128 seq_len:512 free_mem:34.16 GiB
INFO 06-19 08:19:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:19:15 habana_model_runner.py:955] [Warmup][Decode][264/576] batch_size:256 seq_len:256 free_mem:34.16 GiB
INFO 06-19 08:19:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:19:16 habana_model_runner.py:955] [Warmup][Decode][265/576] batch_size:8 seq_len:8064 free_mem:34.16 GiB
INFO 06-19 08:19:16 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:16 habana_model_runner.py:955] [Warmup][Decode][266/576] batch_size:8 seq_len:7936 free_mem:34.16 GiB
INFO 06-19 08:19:16 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:17 habana_model_runner.py:955] [Warmup][Decode][267/576] batch_size:16 seq_len:3968 free_mem:34.16 GiB
INFO 06-19 08:19:17 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:17 habana_model_runner.py:955] [Warmup][Decode][268/576] batch_size:8 seq_len:7808 free_mem:34.16 GiB
INFO 06-19 08:19:17 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:18 habana_model_runner.py:955] [Warmup][Decode][269/576] batch_size:8 seq_len:7680 free_mem:34.16 GiB
INFO 06-19 08:19:18 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:19 habana_model_runner.py:955] [Warmup][Decode][270/576] batch_size:16 seq_len:3840 free_mem:34.16 GiB
INFO 06-19 08:19:19 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:19 habana_model_runner.py:955] [Warmup][Decode][271/576] batch_size:32 seq_len:1920 free_mem:34.16 GiB
INFO 06-19 08:19:19 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:20 habana_model_runner.py:955] [Warmup][Decode][272/576] batch_size:8 seq_len:7552 free_mem:34.16 GiB
INFO 06-19 08:19:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:20 habana_model_runner.py:955] [Warmup][Decode][273/576] batch_size:8 seq_len:7424 free_mem:34.16 GiB
INFO 06-19 08:19:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:21 habana_model_runner.py:955] [Warmup][Decode][274/576] batch_size:16 seq_len:3712 free_mem:34.16 GiB
INFO 06-19 08:19:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:21 habana_model_runner.py:955] [Warmup][Decode][275/576] batch_size:8 seq_len:7296 free_mem:34.16 GiB
INFO 06-19 08:19:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:22 habana_model_runner.py:955] [Warmup][Decode][276/576] batch_size:8 seq_len:7168 free_mem:34.16 GiB
INFO 06-19 08:19:22 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:23 habana_model_runner.py:955] [Warmup][Decode][277/576] batch_size:16 seq_len:3584 free_mem:34.16 GiB
INFO 06-19 08:19:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:23 habana_model_runner.py:955] [Warmup][Decode][278/576] batch_size:32 seq_len:1792 free_mem:34.16 GiB
INFO 06-19 08:19:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:23 habana_model_runner.py:955] [Warmup][Decode][279/576] batch_size:64 seq_len:896 free_mem:34.16 GiB
INFO 06-19 08:19:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:19:24 habana_model_runner.py:955] [Warmup][Decode][280/576] batch_size:8 seq_len:7040 free_mem:34.16 GiB
INFO 06-19 08:19:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:24 habana_model_runner.py:955] [Warmup][Decode][281/576] batch_size:8 seq_len:6912 free_mem:34.16 GiB
INFO 06-19 08:19:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:25 habana_model_runner.py:955] [Warmup][Decode][282/576] batch_size:16 seq_len:3456 free_mem:34.16 GiB
INFO 06-19 08:19:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:26 habana_model_runner.py:955] [Warmup][Decode][283/576] batch_size:8 seq_len:6784 free_mem:34.16 GiB
INFO 06-19 08:19:26 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:26 habana_model_runner.py:955] [Warmup][Decode][284/576] batch_size:8 seq_len:6656 free_mem:34.16 GiB
INFO 06-19 08:19:26 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:27 habana_model_runner.py:955] [Warmup][Decode][285/576] batch_size:16 seq_len:3328 free_mem:34.16 GiB
INFO 06-19 08:19:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:27 habana_model_runner.py:955] [Warmup][Decode][286/576] batch_size:32 seq_len:1664 free_mem:34.16 GiB
INFO 06-19 08:19:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:28 habana_model_runner.py:955] [Warmup][Decode][287/576] batch_size:8 seq_len:6528 free_mem:34.16 GiB
INFO 06-19 08:19:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:28 habana_model_runner.py:955] [Warmup][Decode][288/576] batch_size:8 seq_len:6400 free_mem:34.16 GiB
INFO 06-19 08:19:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:29 habana_model_runner.py:955] [Warmup][Decode][289/576] batch_size:16 seq_len:3200 free_mem:34.16 GiB
INFO 06-19 08:19:29 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:29 habana_model_runner.py:955] [Warmup][Decode][290/576] batch_size:8 seq_len:6272 free_mem:34.16 GiB
INFO 06-19 08:19:29 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:30 habana_model_runner.py:955] [Warmup][Decode][291/576] batch_size:8 seq_len:6144 free_mem:34.16 GiB
INFO 06-19 08:19:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:30 habana_model_runner.py:955] [Warmup][Decode][292/576] batch_size:16 seq_len:3072 free_mem:34.16 GiB
INFO 06-19 08:19:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:31 habana_model_runner.py:955] [Warmup][Decode][293/576] batch_size:32 seq_len:1536 free_mem:34.16 GiB
INFO 06-19 08:19:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:31 habana_model_runner.py:955] [Warmup][Decode][294/576] batch_size:64 seq_len:768 free_mem:34.16 GiB
INFO 06-19 08:19:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:19:32 habana_model_runner.py:955] [Warmup][Decode][295/576] batch_size:128 seq_len:384 free_mem:34.16 GiB
INFO 06-19 08:19:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:19:32 habana_model_runner.py:955] [Warmup][Decode][296/576] batch_size:8 seq_len:6016 free_mem:34.16 GiB
INFO 06-19 08:19:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:33 habana_model_runner.py:955] [Warmup][Decode][297/576] batch_size:8 seq_len:5888 free_mem:34.16 GiB
INFO 06-19 08:19:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:33 habana_model_runner.py:955] [Warmup][Decode][298/576] batch_size:16 seq_len:2944 free_mem:34.16 GiB
INFO 06-19 08:19:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:34 habana_model_runner.py:955] [Warmup][Decode][299/576] batch_size:8 seq_len:5760 free_mem:34.16 GiB
INFO 06-19 08:19:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:34 habana_model_runner.py:955] [Warmup][Decode][300/576] batch_size:8 seq_len:5632 free_mem:34.16 GiB
INFO 06-19 08:19:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:35 habana_model_runner.py:955] [Warmup][Decode][301/576] batch_size:16 seq_len:2816 free_mem:34.16 GiB
INFO 06-19 08:19:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:35 habana_model_runner.py:955] [Warmup][Decode][302/576] batch_size:32 seq_len:1408 free_mem:34.16 GiB
INFO 06-19 08:19:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:36 habana_model_runner.py:955] [Warmup][Decode][303/576] batch_size:8 seq_len:5504 free_mem:34.16 GiB
INFO 06-19 08:19:36 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:37 habana_model_runner.py:955] [Warmup][Decode][304/576] batch_size:8 seq_len:5376 free_mem:34.16 GiB
INFO 06-19 08:19:37 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:37 habana_model_runner.py:955] [Warmup][Decode][305/576] batch_size:16 seq_len:2688 free_mem:34.16 GiB
INFO 06-19 08:19:37 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:38 habana_model_runner.py:955] [Warmup][Decode][306/576] batch_size:8 seq_len:5248 free_mem:34.16 GiB
INFO 06-19 08:19:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:38 habana_model_runner.py:955] [Warmup][Decode][307/576] batch_size:8 seq_len:5120 free_mem:34.16 GiB
INFO 06-19 08:19:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:39 habana_model_runner.py:955] [Warmup][Decode][308/576] batch_size:16 seq_len:2560 free_mem:34.16 GiB
INFO 06-19 08:19:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:39 habana_model_runner.py:955] [Warmup][Decode][309/576] batch_size:32 seq_len:1280 free_mem:34.16 GiB
INFO 06-19 08:19:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:40 habana_model_runner.py:955] [Warmup][Decode][310/576] batch_size:64 seq_len:640 free_mem:34.16 GiB
INFO 06-19 08:19:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:19:40 habana_model_runner.py:955] [Warmup][Decode][311/576] batch_size:8 seq_len:4992 free_mem:34.16 GiB
INFO 06-19 08:19:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:41 habana_model_runner.py:955] [Warmup][Decode][312/576] batch_size:8 seq_len:4864 free_mem:34.16 GiB
INFO 06-19 08:19:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:41 habana_model_runner.py:955] [Warmup][Decode][313/576] batch_size:16 seq_len:2432 free_mem:34.16 GiB
INFO 06-19 08:19:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:42 habana_model_runner.py:955] [Warmup][Decode][314/576] batch_size:8 seq_len:4736 free_mem:34.16 GiB
INFO 06-19 08:19:42 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:42 habana_model_runner.py:955] [Warmup][Decode][315/576] batch_size:8 seq_len:4608 free_mem:34.16 GiB
INFO 06-19 08:19:42 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:43 habana_model_runner.py:955] [Warmup][Decode][316/576] batch_size:16 seq_len:2304 free_mem:34.16 GiB
INFO 06-19 08:19:43 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:43 habana_model_runner.py:955] [Warmup][Decode][317/576] batch_size:32 seq_len:1152 free_mem:34.16 GiB
INFO 06-19 08:19:43 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:44 habana_model_runner.py:955] [Warmup][Decode][318/576] batch_size:8 seq_len:4480 free_mem:34.16 GiB
INFO 06-19 08:19:44 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:44 habana_model_runner.py:955] [Warmup][Decode][319/576] batch_size:8 seq_len:4352 free_mem:34.16 GiB
INFO 06-19 08:19:44 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:45 habana_model_runner.py:955] [Warmup][Decode][320/576] batch_size:16 seq_len:2176 free_mem:34.16 GiB
INFO 06-19 08:19:45 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:45 habana_model_runner.py:955] [Warmup][Decode][321/576] batch_size:8 seq_len:4224 free_mem:34.16 GiB
INFO 06-19 08:19:45 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:46 habana_model_runner.py:955] [Warmup][Decode][322/576] batch_size:4 seq_len:8192 free_mem:34.16 GiB
INFO 06-19 08:19:46 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:46 habana_model_runner.py:955] [Warmup][Decode][323/576] batch_size:8 seq_len:4096 free_mem:34.16 GiB
INFO 06-19 08:19:46 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:47 habana_model_runner.py:955] [Warmup][Decode][324/576] batch_size:16 seq_len:2048 free_mem:34.16 GiB
INFO 06-19 08:19:47 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:47 habana_model_runner.py:955] [Warmup][Decode][325/576] batch_size:32 seq_len:1024 free_mem:34.16 GiB
INFO 06-19 08:19:47 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:48 habana_model_runner.py:955] [Warmup][Decode][326/576] batch_size:64 seq_len:512 free_mem:34.16 GiB
INFO 06-19 08:19:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:19:48 habana_model_runner.py:955] [Warmup][Decode][327/576] batch_size:128 seq_len:256 free_mem:34.16 GiB
INFO 06-19 08:19:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:19:48 habana_model_runner.py:955] [Warmup][Decode][328/576] batch_size:256 seq_len:128 free_mem:34.16 GiB
INFO 06-19 08:19:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([256, 1])
INFO 06-19 08:19:48 habana_model_runner.py:955] [Warmup][Decode][329/576] batch_size:4 seq_len:8064 free_mem:34.16 GiB
INFO 06-19 08:19:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:49 habana_model_runner.py:955] [Warmup][Decode][330/576] batch_size:4 seq_len:7936 free_mem:34.16 GiB
INFO 06-19 08:19:49 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:50 habana_model_runner.py:955] [Warmup][Decode][331/576] batch_size:8 seq_len:3968 free_mem:34.16 GiB
INFO 06-19 08:19:50 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:50 habana_model_runner.py:955] [Warmup][Decode][332/576] batch_size:4 seq_len:7808 free_mem:34.16 GiB
INFO 06-19 08:19:50 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:51 habana_model_runner.py:955] [Warmup][Decode][333/576] batch_size:4 seq_len:7680 free_mem:34.16 GiB
INFO 06-19 08:19:51 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:51 habana_model_runner.py:955] [Warmup][Decode][334/576] batch_size:8 seq_len:3840 free_mem:34.16 GiB
INFO 06-19 08:19:51 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:52 habana_model_runner.py:955] [Warmup][Decode][335/576] batch_size:16 seq_len:1920 free_mem:34.16 GiB
INFO 06-19 08:19:52 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:52 habana_model_runner.py:955] [Warmup][Decode][336/576] batch_size:4 seq_len:7552 free_mem:34.16 GiB
INFO 06-19 08:19:52 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:53 habana_model_runner.py:955] [Warmup][Decode][337/576] batch_size:4 seq_len:7424 free_mem:34.16 GiB
INFO 06-19 08:19:53 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:54 habana_model_runner.py:955] [Warmup][Decode][338/576] batch_size:8 seq_len:3712 free_mem:34.16 GiB
INFO 06-19 08:19:54 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:54 habana_model_runner.py:955] [Warmup][Decode][339/576] batch_size:4 seq_len:7296 free_mem:34.16 GiB
INFO 06-19 08:19:54 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:55 habana_model_runner.py:955] [Warmup][Decode][340/576] batch_size:4 seq_len:7168 free_mem:34.16 GiB
INFO 06-19 08:19:55 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:55 habana_model_runner.py:955] [Warmup][Decode][341/576] batch_size:8 seq_len:3584 free_mem:34.16 GiB
INFO 06-19 08:19:55 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:56 habana_model_runner.py:955] [Warmup][Decode][342/576] batch_size:16 seq_len:1792 free_mem:34.16 GiB
INFO 06-19 08:19:56 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:19:56 habana_model_runner.py:955] [Warmup][Decode][343/576] batch_size:32 seq_len:896 free_mem:34.16 GiB
INFO 06-19 08:19:56 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:19:57 habana_model_runner.py:955] [Warmup][Decode][344/576] batch_size:4 seq_len:7040 free_mem:34.16 GiB
INFO 06-19 08:19:57 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:57 habana_model_runner.py:955] [Warmup][Decode][345/576] batch_size:4 seq_len:6912 free_mem:34.16 GiB
INFO 06-19 08:19:57 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:58 habana_model_runner.py:955] [Warmup][Decode][346/576] batch_size:8 seq_len:3456 free_mem:34.16 GiB
INFO 06-19 08:19:58 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:19:58 habana_model_runner.py:955] [Warmup][Decode][347/576] batch_size:4 seq_len:6784 free_mem:34.16 GiB
INFO 06-19 08:19:58 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:59 habana_model_runner.py:955] [Warmup][Decode][348/576] batch_size:4 seq_len:6656 free_mem:34.16 GiB
INFO 06-19 08:19:59 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:19:59 habana_model_runner.py:955] [Warmup][Decode][349/576] batch_size:8 seq_len:3328 free_mem:34.16 GiB
INFO 06-19 08:19:59 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:00 habana_model_runner.py:955] [Warmup][Decode][350/576] batch_size:16 seq_len:1664 free_mem:34.16 GiB
INFO 06-19 08:20:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:20:00 habana_model_runner.py:955] [Warmup][Decode][351/576] batch_size:4 seq_len:6528 free_mem:34.16 GiB
INFO 06-19 08:20:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:01 habana_model_runner.py:955] [Warmup][Decode][352/576] batch_size:4 seq_len:6400 free_mem:34.16 GiB
INFO 06-19 08:20:01 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:01 habana_model_runner.py:955] [Warmup][Decode][353/576] batch_size:8 seq_len:3200 free_mem:34.16 GiB
INFO 06-19 08:20:01 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:02 habana_model_runner.py:955] [Warmup][Decode][354/576] batch_size:4 seq_len:6272 free_mem:34.16 GiB
INFO 06-19 08:20:02 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:02 habana_model_runner.py:955] [Warmup][Decode][355/576] batch_size:4 seq_len:6144 free_mem:34.16 GiB
INFO 06-19 08:20:02 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:03 habana_model_runner.py:955] [Warmup][Decode][356/576] batch_size:8 seq_len:3072 free_mem:34.16 GiB
INFO 06-19 08:20:03 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:03 habana_model_runner.py:955] [Warmup][Decode][357/576] batch_size:16 seq_len:1536 free_mem:34.16 GiB
INFO 06-19 08:20:03 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:20:04 habana_model_runner.py:955] [Warmup][Decode][358/576] batch_size:32 seq_len:768 free_mem:34.16 GiB
INFO 06-19 08:20:04 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:20:04 habana_model_runner.py:955] [Warmup][Decode][359/576] batch_size:64 seq_len:384 free_mem:34.16 GiB
INFO 06-19 08:20:04 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:20:05 habana_model_runner.py:955] [Warmup][Decode][360/576] batch_size:4 seq_len:6016 free_mem:34.16 GiB
INFO 06-19 08:20:05 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:05 habana_model_runner.py:955] [Warmup][Decode][361/576] batch_size:4 seq_len:5888 free_mem:34.16 GiB
INFO 06-19 08:20:05 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:06 habana_model_runner.py:955] [Warmup][Decode][362/576] batch_size:8 seq_len:2944 free_mem:34.16 GiB
INFO 06-19 08:20:06 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:06 habana_model_runner.py:955] [Warmup][Decode][363/576] batch_size:4 seq_len:5760 free_mem:34.16 GiB
INFO 06-19 08:20:06 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:07 habana_model_runner.py:955] [Warmup][Decode][364/576] batch_size:4 seq_len:5632 free_mem:34.16 GiB
INFO 06-19 08:20:07 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:08 habana_model_runner.py:955] [Warmup][Decode][365/576] batch_size:8 seq_len:2816 free_mem:34.16 GiB
INFO 06-19 08:20:08 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:08 habana_model_runner.py:955] [Warmup][Decode][366/576] batch_size:16 seq_len:1408 free_mem:34.16 GiB
INFO 06-19 08:20:08 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:20:09 habana_model_runner.py:955] [Warmup][Decode][367/576] batch_size:4 seq_len:5504 free_mem:34.16 GiB
INFO 06-19 08:20:09 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:09 habana_model_runner.py:955] [Warmup][Decode][368/576] batch_size:4 seq_len:5376 free_mem:34.16 GiB
INFO 06-19 08:20:09 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:10 habana_model_runner.py:955] [Warmup][Decode][369/576] batch_size:8 seq_len:2688 free_mem:34.16 GiB
INFO 06-19 08:20:10 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:10 habana_model_runner.py:955] [Warmup][Decode][370/576] batch_size:4 seq_len:5248 free_mem:34.16 GiB
INFO 06-19 08:20:10 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:11 habana_model_runner.py:955] [Warmup][Decode][371/576] batch_size:4 seq_len:5120 free_mem:34.16 GiB
INFO 06-19 08:20:11 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:11 habana_model_runner.py:955] [Warmup][Decode][372/576] batch_size:8 seq_len:2560 free_mem:34.16 GiB
INFO 06-19 08:20:11 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:12 habana_model_runner.py:955] [Warmup][Decode][373/576] batch_size:16 seq_len:1280 free_mem:34.16 GiB
INFO 06-19 08:20:12 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:20:12 habana_model_runner.py:955] [Warmup][Decode][374/576] batch_size:32 seq_len:640 free_mem:34.16 GiB
INFO 06-19 08:20:12 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:20:13 habana_model_runner.py:955] [Warmup][Decode][375/576] batch_size:4 seq_len:4992 free_mem:34.16 GiB
INFO 06-19 08:20:13 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:13 habana_model_runner.py:955] [Warmup][Decode][376/576] batch_size:4 seq_len:4864 free_mem:34.16 GiB
INFO 06-19 08:20:13 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:14 habana_model_runner.py:955] [Warmup][Decode][377/576] batch_size:8 seq_len:2432 free_mem:34.16 GiB
INFO 06-19 08:20:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:14 habana_model_runner.py:955] [Warmup][Decode][378/576] batch_size:4 seq_len:4736 free_mem:34.16 GiB
INFO 06-19 08:20:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:15 habana_model_runner.py:955] [Warmup][Decode][379/576] batch_size:4 seq_len:4608 free_mem:34.16 GiB
INFO 06-19 08:20:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:15 habana_model_runner.py:955] [Warmup][Decode][380/576] batch_size:8 seq_len:2304 free_mem:34.16 GiB
INFO 06-19 08:20:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:15 habana_model_runner.py:955] [Warmup][Decode][381/576] batch_size:16 seq_len:1152 free_mem:34.16 GiB
INFO 06-19 08:20:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:20:16 habana_model_runner.py:955] [Warmup][Decode][382/576] batch_size:4 seq_len:4480 free_mem:34.16 GiB
INFO 06-19 08:20:16 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:17 habana_model_runner.py:955] [Warmup][Decode][383/576] batch_size:4 seq_len:4352 free_mem:34.16 GiB
INFO 06-19 08:20:17 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:17 habana_model_runner.py:955] [Warmup][Decode][384/576] batch_size:8 seq_len:2176 free_mem:34.16 GiB
INFO 06-19 08:20:17 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:18 habana_model_runner.py:955] [Warmup][Decode][385/576] batch_size:4 seq_len:4224 free_mem:34.16 GiB
INFO 06-19 08:20:18 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:18 habana_model_runner.py:955] [Warmup][Decode][386/576] batch_size:2 seq_len:8192 free_mem:34.16 GiB
INFO 06-19 08:20:18 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:19 habana_model_runner.py:955] [Warmup][Decode][387/576] batch_size:4 seq_len:4096 free_mem:34.16 GiB
INFO 06-19 08:20:19 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:19 habana_model_runner.py:955] [Warmup][Decode][388/576] batch_size:8 seq_len:2048 free_mem:34.16 GiB
INFO 06-19 08:20:19 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:20 habana_model_runner.py:955] [Warmup][Decode][389/576] batch_size:16 seq_len:1024 free_mem:34.16 GiB
INFO 06-19 08:20:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:20:20 habana_model_runner.py:955] [Warmup][Decode][390/576] batch_size:32 seq_len:512 free_mem:34.16 GiB
INFO 06-19 08:20:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:20:20 habana_model_runner.py:955] [Warmup][Decode][391/576] batch_size:64 seq_len:256 free_mem:34.16 GiB
INFO 06-19 08:20:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:20:21 habana_model_runner.py:955] [Warmup][Decode][392/576] batch_size:128 seq_len:128 free_mem:34.16 GiB
INFO 06-19 08:20:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([128, 1])
INFO 06-19 08:20:21 habana_model_runner.py:955] [Warmup][Decode][393/576] batch_size:2 seq_len:8064 free_mem:34.16 GiB
INFO 06-19 08:20:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:21 habana_model_runner.py:955] [Warmup][Decode][394/576] batch_size:2 seq_len:7936 free_mem:34.16 GiB
INFO 06-19 08:20:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:22 habana_model_runner.py:955] [Warmup][Decode][395/576] batch_size:4 seq_len:3968 free_mem:34.16 GiB
INFO 06-19 08:20:22 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:23 habana_model_runner.py:955] [Warmup][Decode][396/576] batch_size:2 seq_len:7808 free_mem:34.16 GiB
INFO 06-19 08:20:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:23 habana_model_runner.py:955] [Warmup][Decode][397/576] batch_size:2 seq_len:7680 free_mem:34.16 GiB
INFO 06-19 08:20:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:24 habana_model_runner.py:955] [Warmup][Decode][398/576] batch_size:4 seq_len:3840 free_mem:34.16 GiB
INFO 06-19 08:20:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:24 habana_model_runner.py:955] [Warmup][Decode][399/576] batch_size:8 seq_len:1920 free_mem:34.16 GiB
INFO 06-19 08:20:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:25 habana_model_runner.py:955] [Warmup][Decode][400/576] batch_size:2 seq_len:7552 free_mem:34.16 GiB
INFO 06-19 08:20:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:25 habana_model_runner.py:955] [Warmup][Decode][401/576] batch_size:2 seq_len:7424 free_mem:34.16 GiB
INFO 06-19 08:20:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:26 habana_model_runner.py:955] [Warmup][Decode][402/576] batch_size:4 seq_len:3712 free_mem:34.16 GiB
INFO 06-19 08:20:26 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:26 habana_model_runner.py:955] [Warmup][Decode][403/576] batch_size:2 seq_len:7296 free_mem:34.16 GiB
INFO 06-19 08:20:26 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:27 habana_model_runner.py:955] [Warmup][Decode][404/576] batch_size:2 seq_len:7168 free_mem:34.16 GiB
INFO 06-19 08:20:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:28 habana_model_runner.py:955] [Warmup][Decode][405/576] batch_size:4 seq_len:3584 free_mem:34.16 GiB
INFO 06-19 08:20:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:28 habana_model_runner.py:955] [Warmup][Decode][406/576] batch_size:8 seq_len:1792 free_mem:34.16 GiB
INFO 06-19 08:20:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:28 habana_model_runner.py:955] [Warmup][Decode][407/576] batch_size:16 seq_len:896 free_mem:34.16 GiB
INFO 06-19 08:20:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:20:29 habana_model_runner.py:955] [Warmup][Decode][408/576] batch_size:2 seq_len:7040 free_mem:34.16 GiB
INFO 06-19 08:20:29 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:29 habana_model_runner.py:955] [Warmup][Decode][409/576] batch_size:2 seq_len:6912 free_mem:34.16 GiB
INFO 06-19 08:20:29 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:30 habana_model_runner.py:955] [Warmup][Decode][410/576] batch_size:4 seq_len:3456 free_mem:34.16 GiB
INFO 06-19 08:20:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:31 habana_model_runner.py:955] [Warmup][Decode][411/576] batch_size:2 seq_len:6784 free_mem:34.16 GiB
INFO 06-19 08:20:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:31 habana_model_runner.py:955] [Warmup][Decode][412/576] batch_size:2 seq_len:6656 free_mem:34.16 GiB
INFO 06-19 08:20:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:32 habana_model_runner.py:955] [Warmup][Decode][413/576] batch_size:4 seq_len:3328 free_mem:34.16 GiB
INFO 06-19 08:20:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:32 habana_model_runner.py:955] [Warmup][Decode][414/576] batch_size:8 seq_len:1664 free_mem:34.16 GiB
INFO 06-19 08:20:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:32 habana_model_runner.py:955] [Warmup][Decode][415/576] batch_size:2 seq_len:6528 free_mem:34.16 GiB
INFO 06-19 08:20:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:33 habana_model_runner.py:955] [Warmup][Decode][416/576] batch_size:2 seq_len:6400 free_mem:34.16 GiB
INFO 06-19 08:20:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:34 habana_model_runner.py:955] [Warmup][Decode][417/576] batch_size:4 seq_len:3200 free_mem:34.16 GiB
INFO 06-19 08:20:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:34 habana_model_runner.py:955] [Warmup][Decode][418/576] batch_size:2 seq_len:6272 free_mem:34.16 GiB
INFO 06-19 08:20:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:35 habana_model_runner.py:955] [Warmup][Decode][419/576] batch_size:2 seq_len:6144 free_mem:34.16 GiB
INFO 06-19 08:20:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:35 habana_model_runner.py:955] [Warmup][Decode][420/576] batch_size:4 seq_len:3072 free_mem:34.16 GiB
INFO 06-19 08:20:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:36 habana_model_runner.py:955] [Warmup][Decode][421/576] batch_size:8 seq_len:1536 free_mem:34.16 GiB
INFO 06-19 08:20:36 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:36 habana_model_runner.py:955] [Warmup][Decode][422/576] batch_size:16 seq_len:768 free_mem:34.16 GiB
INFO 06-19 08:20:36 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:20:37 habana_model_runner.py:955] [Warmup][Decode][423/576] batch_size:32 seq_len:384 free_mem:34.16 GiB
INFO 06-19 08:20:37 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:20:37 habana_model_runner.py:955] [Warmup][Decode][424/576] batch_size:2 seq_len:6016 free_mem:34.16 GiB
INFO 06-19 08:20:37 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:38 habana_model_runner.py:955] [Warmup][Decode][425/576] batch_size:2 seq_len:5888 free_mem:34.16 GiB
INFO 06-19 08:20:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:38 habana_model_runner.py:955] [Warmup][Decode][426/576] batch_size:4 seq_len:2944 free_mem:34.16 GiB
INFO 06-19 08:20:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:39 habana_model_runner.py:955] [Warmup][Decode][427/576] batch_size:2 seq_len:5760 free_mem:34.16 GiB
INFO 06-19 08:20:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:39 habana_model_runner.py:955] [Warmup][Decode][428/576] batch_size:2 seq_len:5632 free_mem:34.16 GiB
INFO 06-19 08:20:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:40 habana_model_runner.py:955] [Warmup][Decode][429/576] batch_size:4 seq_len:2816 free_mem:34.16 GiB
INFO 06-19 08:20:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:40 habana_model_runner.py:955] [Warmup][Decode][430/576] batch_size:8 seq_len:1408 free_mem:34.16 GiB
INFO 06-19 08:20:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:41 habana_model_runner.py:955] [Warmup][Decode][431/576] batch_size:2 seq_len:5504 free_mem:34.16 GiB
INFO 06-19 08:20:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:41 habana_model_runner.py:955] [Warmup][Decode][432/576] batch_size:2 seq_len:5376 free_mem:34.16 GiB
INFO 06-19 08:20:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:42 habana_model_runner.py:955] [Warmup][Decode][433/576] batch_size:4 seq_len:2688 free_mem:34.16 GiB
INFO 06-19 08:20:42 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:42 habana_model_runner.py:955] [Warmup][Decode][434/576] batch_size:2 seq_len:5248 free_mem:34.16 GiB
INFO 06-19 08:20:42 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:43 habana_model_runner.py:955] [Warmup][Decode][435/576] batch_size:2 seq_len:5120 free_mem:34.16 GiB
INFO 06-19 08:20:43 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:43 habana_model_runner.py:955] [Warmup][Decode][436/576] batch_size:4 seq_len:2560 free_mem:34.16 GiB
INFO 06-19 08:20:43 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:44 habana_model_runner.py:955] [Warmup][Decode][437/576] batch_size:8 seq_len:1280 free_mem:34.16 GiB
INFO 06-19 08:20:44 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:44 habana_model_runner.py:955] [Warmup][Decode][438/576] batch_size:16 seq_len:640 free_mem:34.16 GiB
INFO 06-19 08:20:44 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:20:45 habana_model_runner.py:955] [Warmup][Decode][439/576] batch_size:2 seq_len:4992 free_mem:34.16 GiB
INFO 06-19 08:20:45 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:45 habana_model_runner.py:955] [Warmup][Decode][440/576] batch_size:2 seq_len:4864 free_mem:34.16 GiB
INFO 06-19 08:20:45 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:46 habana_model_runner.py:955] [Warmup][Decode][441/576] batch_size:4 seq_len:2432 free_mem:34.16 GiB
INFO 06-19 08:20:46 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:46 habana_model_runner.py:955] [Warmup][Decode][442/576] batch_size:2 seq_len:4736 free_mem:34.16 GiB
INFO 06-19 08:20:46 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:47 habana_model_runner.py:955] [Warmup][Decode][443/576] batch_size:2 seq_len:4608 free_mem:34.16 GiB
INFO 06-19 08:20:47 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:47 habana_model_runner.py:955] [Warmup][Decode][444/576] batch_size:4 seq_len:2304 free_mem:34.16 GiB
INFO 06-19 08:20:47 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:48 habana_model_runner.py:955] [Warmup][Decode][445/576] batch_size:8 seq_len:1152 free_mem:34.16 GiB
INFO 06-19 08:20:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:48 habana_model_runner.py:955] [Warmup][Decode][446/576] batch_size:2 seq_len:4480 free_mem:34.16 GiB
INFO 06-19 08:20:48 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:49 habana_model_runner.py:955] [Warmup][Decode][447/576] batch_size:2 seq_len:4352 free_mem:34.16 GiB
INFO 06-19 08:20:49 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:49 habana_model_runner.py:955] [Warmup][Decode][448/576] batch_size:4 seq_len:2176 free_mem:34.16 GiB
INFO 06-19 08:20:49 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:50 habana_model_runner.py:955] [Warmup][Decode][449/576] batch_size:2 seq_len:4224 free_mem:34.16 GiB
INFO 06-19 08:20:50 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:50 habana_model_runner.py:955] [Warmup][Decode][450/576] batch_size:1 seq_len:8192 free_mem:34.16 GiB
INFO 06-19 08:20:50 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:20:51 habana_model_runner.py:955] [Warmup][Decode][451/576] batch_size:2 seq_len:4096 free_mem:34.16 GiB
INFO 06-19 08:20:51 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:51 habana_model_runner.py:955] [Warmup][Decode][452/576] batch_size:4 seq_len:2048 free_mem:34.16 GiB
INFO 06-19 08:20:51 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:52 habana_model_runner.py:955] [Warmup][Decode][453/576] batch_size:8 seq_len:1024 free_mem:34.16 GiB
INFO 06-19 08:20:52 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:20:52 habana_model_runner.py:955] [Warmup][Decode][454/576] batch_size:16 seq_len:512 free_mem:34.16 GiB
INFO 06-19 08:20:52 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:20:52 habana_model_runner.py:955] [Warmup][Decode][455/576] batch_size:32 seq_len:256 free_mem:34.16 GiB
INFO 06-19 08:20:52 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:20:53 habana_model_runner.py:955] [Warmup][Decode][456/576] batch_size:64 seq_len:128 free_mem:34.16 GiB
INFO 06-19 08:20:53 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([64, 1])
INFO 06-19 08:20:53 habana_model_runner.py:955] [Warmup][Decode][457/576] batch_size:1 seq_len:8064 free_mem:34.16 GiB
INFO 06-19 08:20:53 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:20:53 habana_model_runner.py:955] [Warmup][Decode][458/576] batch_size:1 seq_len:7936 free_mem:34.16 GiB
INFO 06-19 08:20:53 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:20:54 habana_model_runner.py:955] [Warmup][Decode][459/576] batch_size:2 seq_len:3968 free_mem:34.16 GiB
INFO 06-19 08:20:54 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:54 habana_model_runner.py:955] [Warmup][Decode][460/576] batch_size:1 seq_len:7808 free_mem:34.16 GiB
INFO 06-19 08:20:54 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:20:55 habana_model_runner.py:955] [Warmup][Decode][461/576] batch_size:1 seq_len:7680 free_mem:34.16 GiB
INFO 06-19 08:20:55 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:20:56 habana_model_runner.py:955] [Warmup][Decode][462/576] batch_size:2 seq_len:3840 free_mem:34.16 GiB
INFO 06-19 08:20:56 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:56 habana_model_runner.py:955] [Warmup][Decode][463/576] batch_size:4 seq_len:1920 free_mem:34.16 GiB
INFO 06-19 08:20:56 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:20:57 habana_model_runner.py:955] [Warmup][Decode][464/576] batch_size:1 seq_len:7552 free_mem:34.16 GiB
INFO 06-19 08:20:57 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:20:57 habana_model_runner.py:955] [Warmup][Decode][465/576] batch_size:1 seq_len:7424 free_mem:34.16 GiB
INFO 06-19 08:20:57 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:20:58 habana_model_runner.py:955] [Warmup][Decode][466/576] batch_size:2 seq_len:3712 free_mem:34.16 GiB
INFO 06-19 08:20:58 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:20:58 habana_model_runner.py:955] [Warmup][Decode][467/576] batch_size:1 seq_len:7296 free_mem:34.16 GiB
INFO 06-19 08:20:58 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:20:59 habana_model_runner.py:955] [Warmup][Decode][468/576] batch_size:1 seq_len:7168 free_mem:34.16 GiB
INFO 06-19 08:20:59 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:20:59 habana_model_runner.py:955] [Warmup][Decode][469/576] batch_size:2 seq_len:3584 free_mem:34.16 GiB
INFO 06-19 08:20:59 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:00 habana_model_runner.py:955] [Warmup][Decode][470/576] batch_size:4 seq_len:1792 free_mem:34.16 GiB
INFO 06-19 08:21:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:00 habana_model_runner.py:955] [Warmup][Decode][471/576] batch_size:8 seq_len:896 free_mem:34.16 GiB
INFO 06-19 08:21:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:21:00 habana_model_runner.py:955] [Warmup][Decode][472/576] batch_size:1 seq_len:7040 free_mem:34.16 GiB
INFO 06-19 08:21:00 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:01 habana_model_runner.py:955] [Warmup][Decode][473/576] batch_size:1 seq_len:6912 free_mem:34.16 GiB
INFO 06-19 08:21:01 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:02 habana_model_runner.py:955] [Warmup][Decode][474/576] batch_size:2 seq_len:3456 free_mem:34.16 GiB
INFO 06-19 08:21:02 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:02 habana_model_runner.py:955] [Warmup][Decode][475/576] batch_size:1 seq_len:6784 free_mem:34.16 GiB
INFO 06-19 08:21:02 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:03 habana_model_runner.py:955] [Warmup][Decode][476/576] batch_size:1 seq_len:6656 free_mem:34.16 GiB
INFO 06-19 08:21:03 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:03 habana_model_runner.py:955] [Warmup][Decode][477/576] batch_size:2 seq_len:3328 free_mem:34.16 GiB
INFO 06-19 08:21:03 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:03 habana_model_runner.py:955] [Warmup][Decode][478/576] batch_size:4 seq_len:1664 free_mem:34.16 GiB
INFO 06-19 08:21:03 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:04 habana_model_runner.py:955] [Warmup][Decode][479/576] batch_size:1 seq_len:6528 free_mem:34.16 GiB
INFO 06-19 08:21:04 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:04 habana_model_runner.py:955] [Warmup][Decode][480/576] batch_size:1 seq_len:6400 free_mem:34.16 GiB
INFO 06-19 08:21:04 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:05 habana_model_runner.py:955] [Warmup][Decode][481/576] batch_size:2 seq_len:3200 free_mem:34.16 GiB
INFO 06-19 08:21:05 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:05 habana_model_runner.py:955] [Warmup][Decode][482/576] batch_size:1 seq_len:6272 free_mem:34.16 GiB
INFO 06-19 08:21:05 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:06 habana_model_runner.py:955] [Warmup][Decode][483/576] batch_size:1 seq_len:6144 free_mem:34.16 GiB
INFO 06-19 08:21:06 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:06 habana_model_runner.py:955] [Warmup][Decode][484/576] batch_size:2 seq_len:3072 free_mem:34.16 GiB
INFO 06-19 08:21:06 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:07 habana_model_runner.py:955] [Warmup][Decode][485/576] batch_size:4 seq_len:1536 free_mem:34.16 GiB
INFO 06-19 08:21:07 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:07 habana_model_runner.py:955] [Warmup][Decode][486/576] batch_size:8 seq_len:768 free_mem:34.16 GiB
INFO 06-19 08:21:07 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:21:08 habana_model_runner.py:955] [Warmup][Decode][487/576] batch_size:16 seq_len:384 free_mem:34.16 GiB
INFO 06-19 08:21:08 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:21:08 habana_model_runner.py:955] [Warmup][Decode][488/576] batch_size:1 seq_len:6016 free_mem:34.16 GiB
INFO 06-19 08:21:08 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:09 habana_model_runner.py:955] [Warmup][Decode][489/576] batch_size:1 seq_len:5888 free_mem:34.16 GiB
INFO 06-19 08:21:09 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:09 habana_model_runner.py:955] [Warmup][Decode][490/576] batch_size:2 seq_len:2944 free_mem:34.16 GiB
INFO 06-19 08:21:09 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:10 habana_model_runner.py:955] [Warmup][Decode][491/576] batch_size:1 seq_len:5760 free_mem:34.16 GiB
INFO 06-19 08:21:10 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:10 habana_model_runner.py:955] [Warmup][Decode][492/576] batch_size:1 seq_len:5632 free_mem:34.16 GiB
INFO 06-19 08:21:10 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:11 habana_model_runner.py:955] [Warmup][Decode][493/576] batch_size:2 seq_len:2816 free_mem:34.16 GiB
INFO 06-19 08:21:11 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:11 habana_model_runner.py:955] [Warmup][Decode][494/576] batch_size:4 seq_len:1408 free_mem:34.16 GiB
INFO 06-19 08:21:11 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:12 habana_model_runner.py:955] [Warmup][Decode][495/576] batch_size:1 seq_len:5504 free_mem:34.16 GiB
INFO 06-19 08:21:12 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:12 habana_model_runner.py:955] [Warmup][Decode][496/576] batch_size:1 seq_len:5376 free_mem:34.16 GiB
INFO 06-19 08:21:12 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:13 habana_model_runner.py:955] [Warmup][Decode][497/576] batch_size:2 seq_len:2688 free_mem:34.16 GiB
INFO 06-19 08:21:13 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:13 habana_model_runner.py:955] [Warmup][Decode][498/576] batch_size:1 seq_len:5248 free_mem:34.16 GiB
INFO 06-19 08:21:13 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:14 habana_model_runner.py:955] [Warmup][Decode][499/576] batch_size:1 seq_len:5120 free_mem:34.16 GiB
INFO 06-19 08:21:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:14 habana_model_runner.py:955] [Warmup][Decode][500/576] batch_size:2 seq_len:2560 free_mem:34.16 GiB
INFO 06-19 08:21:14 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:15 habana_model_runner.py:955] [Warmup][Decode][501/576] batch_size:4 seq_len:1280 free_mem:34.16 GiB
INFO 06-19 08:21:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:15 habana_model_runner.py:955] [Warmup][Decode][502/576] batch_size:8 seq_len:640 free_mem:34.16 GiB
INFO 06-19 08:21:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:21:15 habana_model_runner.py:955] [Warmup][Decode][503/576] batch_size:1 seq_len:4992 free_mem:34.16 GiB
INFO 06-19 08:21:15 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:16 habana_model_runner.py:955] [Warmup][Decode][504/576] batch_size:1 seq_len:4864 free_mem:34.16 GiB
INFO 06-19 08:21:16 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:16 habana_model_runner.py:955] [Warmup][Decode][505/576] batch_size:2 seq_len:2432 free_mem:34.16 GiB
INFO 06-19 08:21:16 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:17 habana_model_runner.py:955] [Warmup][Decode][506/576] batch_size:1 seq_len:4736 free_mem:34.16 GiB
INFO 06-19 08:21:17 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:17 habana_model_runner.py:955] [Warmup][Decode][507/576] batch_size:1 seq_len:4608 free_mem:34.16 GiB
INFO 06-19 08:21:17 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:18 habana_model_runner.py:955] [Warmup][Decode][508/576] batch_size:2 seq_len:2304 free_mem:34.16 GiB
INFO 06-19 08:21:18 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:18 habana_model_runner.py:955] [Warmup][Decode][509/576] batch_size:4 seq_len:1152 free_mem:34.16 GiB
INFO 06-19 08:21:18 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:19 habana_model_runner.py:955] [Warmup][Decode][510/576] batch_size:1 seq_len:4480 free_mem:34.16 GiB
INFO 06-19 08:21:19 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:19 habana_model_runner.py:955] [Warmup][Decode][511/576] batch_size:1 seq_len:4352 free_mem:34.16 GiB
INFO 06-19 08:21:19 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:20 habana_model_runner.py:955] [Warmup][Decode][512/576] batch_size:2 seq_len:2176 free_mem:34.16 GiB
INFO 06-19 08:21:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:20 habana_model_runner.py:955] [Warmup][Decode][513/576] batch_size:1 seq_len:4224 free_mem:34.16 GiB
INFO 06-19 08:21:20 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:21 habana_model_runner.py:955] [Warmup][Decode][514/576] batch_size:1 seq_len:4096 free_mem:34.16 GiB
INFO 06-19 08:21:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:21 habana_model_runner.py:955] [Warmup][Decode][515/576] batch_size:2 seq_len:2048 free_mem:34.16 GiB
INFO 06-19 08:21:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:21 habana_model_runner.py:955] [Warmup][Decode][516/576] batch_size:4 seq_len:1024 free_mem:34.16 GiB
INFO 06-19 08:21:21 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:22 habana_model_runner.py:955] [Warmup][Decode][517/576] batch_size:8 seq_len:512 free_mem:34.16 GiB
INFO 06-19 08:21:22 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:21:22 habana_model_runner.py:955] [Warmup][Decode][518/576] batch_size:16 seq_len:256 free_mem:34.16 GiB
INFO 06-19 08:21:22 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:21:22 habana_model_runner.py:955] [Warmup][Decode][519/576] batch_size:32 seq_len:128 free_mem:34.16 GiB
INFO 06-19 08:21:22 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([32, 1])
INFO 06-19 08:21:22 habana_model_runner.py:955] [Warmup][Decode][520/576] batch_size:1 seq_len:3968 free_mem:34.16 GiB
INFO 06-19 08:21:22 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:23 habana_model_runner.py:955] [Warmup][Decode][521/576] batch_size:1 seq_len:3840 free_mem:34.16 GiB
INFO 06-19 08:21:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:23 habana_model_runner.py:955] [Warmup][Decode][522/576] batch_size:2 seq_len:1920 free_mem:34.16 GiB
INFO 06-19 08:21:23 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:24 habana_model_runner.py:955] [Warmup][Decode][523/576] batch_size:1 seq_len:3712 free_mem:34.16 GiB
INFO 06-19 08:21:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:24 habana_model_runner.py:955] [Warmup][Decode][524/576] batch_size:1 seq_len:3584 free_mem:34.16 GiB
INFO 06-19 08:21:24 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:25 habana_model_runner.py:955] [Warmup][Decode][525/576] batch_size:2 seq_len:1792 free_mem:34.16 GiB
INFO 06-19 08:21:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:25 habana_model_runner.py:955] [Warmup][Decode][526/576] batch_size:4 seq_len:896 free_mem:34.16 GiB
INFO 06-19 08:21:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:25 habana_model_runner.py:955] [Warmup][Decode][527/576] batch_size:1 seq_len:3456 free_mem:34.16 GiB
INFO 06-19 08:21:25 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:26 habana_model_runner.py:955] [Warmup][Decode][528/576] batch_size:1 seq_len:3328 free_mem:34.16 GiB
INFO 06-19 08:21:26 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:26 habana_model_runner.py:955] [Warmup][Decode][529/576] batch_size:2 seq_len:1664 free_mem:34.16 GiB
INFO 06-19 08:21:26 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:27 habana_model_runner.py:955] [Warmup][Decode][530/576] batch_size:1 seq_len:3200 free_mem:34.16 GiB
INFO 06-19 08:21:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:27 habana_model_runner.py:955] [Warmup][Decode][531/576] batch_size:1 seq_len:3072 free_mem:34.16 GiB
INFO 06-19 08:21:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:27 habana_model_runner.py:955] [Warmup][Decode][532/576] batch_size:2 seq_len:1536 free_mem:34.16 GiB
INFO 06-19 08:21:27 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:28 habana_model_runner.py:955] [Warmup][Decode][533/576] batch_size:4 seq_len:768 free_mem:34.16 GiB
INFO 06-19 08:21:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:28 habana_model_runner.py:955] [Warmup][Decode][534/576] batch_size:8 seq_len:384 free_mem:34.16 GiB
INFO 06-19 08:21:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:21:28 habana_model_runner.py:955] [Warmup][Decode][535/576] batch_size:1 seq_len:2944 free_mem:34.16 GiB
INFO 06-19 08:21:28 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:29 habana_model_runner.py:955] [Warmup][Decode][536/576] batch_size:1 seq_len:2816 free_mem:34.16 GiB
INFO 06-19 08:21:29 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:29 habana_model_runner.py:955] [Warmup][Decode][537/576] batch_size:2 seq_len:1408 free_mem:34.16 GiB
INFO 06-19 08:21:29 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:30 habana_model_runner.py:955] [Warmup][Decode][538/576] batch_size:1 seq_len:2688 free_mem:34.16 GiB
INFO 06-19 08:21:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:30 habana_model_runner.py:955] [Warmup][Decode][539/576] batch_size:1 seq_len:2560 free_mem:34.16 GiB
INFO 06-19 08:21:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:30 habana_model_runner.py:955] [Warmup][Decode][540/576] batch_size:2 seq_len:1280 free_mem:34.16 GiB
INFO 06-19 08:21:30 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:31 habana_model_runner.py:955] [Warmup][Decode][541/576] batch_size:4 seq_len:640 free_mem:34.16 GiB
INFO 06-19 08:21:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:31 habana_model_runner.py:955] [Warmup][Decode][542/576] batch_size:1 seq_len:2432 free_mem:34.16 GiB
INFO 06-19 08:21:31 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:32 habana_model_runner.py:955] [Warmup][Decode][543/576] batch_size:1 seq_len:2304 free_mem:34.16 GiB
INFO 06-19 08:21:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:32 habana_model_runner.py:955] [Warmup][Decode][544/576] batch_size:2 seq_len:1152 free_mem:34.16 GiB
INFO 06-19 08:21:32 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:33 habana_model_runner.py:955] [Warmup][Decode][545/576] batch_size:1 seq_len:2176 free_mem:34.16 GiB
INFO 06-19 08:21:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:33 habana_model_runner.py:955] [Warmup][Decode][546/576] batch_size:1 seq_len:2048 free_mem:34.16 GiB
INFO 06-19 08:21:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:33 habana_model_runner.py:955] [Warmup][Decode][547/576] batch_size:2 seq_len:1024 free_mem:34.16 GiB
INFO 06-19 08:21:33 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:34 habana_model_runner.py:955] [Warmup][Decode][548/576] batch_size:4 seq_len:512 free_mem:34.16 GiB
INFO 06-19 08:21:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:34 habana_model_runner.py:955] [Warmup][Decode][549/576] batch_size:8 seq_len:256 free_mem:34.16 GiB
INFO 06-19 08:21:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:21:34 habana_model_runner.py:955] [Warmup][Decode][550/576] batch_size:16 seq_len:128 free_mem:34.16 GiB
INFO 06-19 08:21:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([16, 1])
INFO 06-19 08:21:34 habana_model_runner.py:955] [Warmup][Decode][551/576] batch_size:1 seq_len:1920 free_mem:34.16 GiB
INFO 06-19 08:21:34 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:35 habana_model_runner.py:955] [Warmup][Decode][552/576] batch_size:1 seq_len:1792 free_mem:34.16 GiB
INFO 06-19 08:21:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:35 habana_model_runner.py:955] [Warmup][Decode][553/576] batch_size:2 seq_len:896 free_mem:34.16 GiB
INFO 06-19 08:21:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:35 habana_model_runner.py:955] [Warmup][Decode][554/576] batch_size:1 seq_len:1664 free_mem:34.16 GiB
INFO 06-19 08:21:35 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:36 habana_model_runner.py:955] [Warmup][Decode][555/576] batch_size:1 seq_len:1536 free_mem:34.16 GiB
INFO 06-19 08:21:36 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:36 habana_model_runner.py:955] [Warmup][Decode][556/576] batch_size:2 seq_len:768 free_mem:34.16 GiB
INFO 06-19 08:21:36 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:36 habana_model_runner.py:955] [Warmup][Decode][557/576] batch_size:4 seq_len:384 free_mem:34.16 GiB
INFO 06-19 08:21:36 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:37 habana_model_runner.py:955] [Warmup][Decode][558/576] batch_size:1 seq_len:1408 free_mem:34.16 GiB
INFO 06-19 08:21:37 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:37 habana_model_runner.py:955] [Warmup][Decode][559/576] batch_size:1 seq_len:1280 free_mem:34.16 GiB
INFO 06-19 08:21:37 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:37 habana_model_runner.py:955] [Warmup][Decode][560/576] batch_size:2 seq_len:640 free_mem:34.16 GiB
INFO 06-19 08:21:37 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:38 habana_model_runner.py:955] [Warmup][Decode][561/576] batch_size:1 seq_len:1152 free_mem:34.16 GiB
INFO 06-19 08:21:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:38 habana_model_runner.py:955] [Warmup][Decode][562/576] batch_size:1 seq_len:1024 free_mem:34.16 GiB
INFO 06-19 08:21:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:38 habana_model_runner.py:955] [Warmup][Decode][563/576] batch_size:2 seq_len:512 free_mem:34.16 GiB
INFO 06-19 08:21:38 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:39 habana_model_runner.py:955] [Warmup][Decode][564/576] batch_size:4 seq_len:256 free_mem:34.16 GiB
INFO 06-19 08:21:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:39 habana_model_runner.py:955] [Warmup][Decode][565/576] batch_size:8 seq_len:128 free_mem:34.16 GiB
INFO 06-19 08:21:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([8, 1])
INFO 06-19 08:21:39 habana_model_runner.py:955] [Warmup][Decode][566/576] batch_size:1 seq_len:896 free_mem:34.16 GiB
INFO 06-19 08:21:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:39 habana_model_runner.py:955] [Warmup][Decode][567/576] batch_size:1 seq_len:768 free_mem:34.16 GiB
INFO 06-19 08:21:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:39 habana_model_runner.py:955] [Warmup][Decode][568/576] batch_size:2 seq_len:384 free_mem:34.16 GiB
INFO 06-19 08:21:39 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:40 habana_model_runner.py:955] [Warmup][Decode][569/576] batch_size:1 seq_len:640 free_mem:34.16 GiB
INFO 06-19 08:21:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:40 habana_model_runner.py:955] [Warmup][Decode][570/576] batch_size:1 seq_len:512 free_mem:34.16 GiB
INFO 06-19 08:21:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:40 habana_model_runner.py:955] [Warmup][Decode][571/576] batch_size:2 seq_len:256 free_mem:34.16 GiB
INFO 06-19 08:21:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:40 habana_model_runner.py:955] [Warmup][Decode][572/576] batch_size:4 seq_len:128 free_mem:34.16 GiB
INFO 06-19 08:21:40 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([4, 1])
INFO 06-19 08:21:41 habana_model_runner.py:955] [Warmup][Decode][573/576] batch_size:1 seq_len:384 free_mem:34.16 GiB
INFO 06-19 08:21:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:41 habana_model_runner.py:955] [Warmup][Decode][574/576] batch_size:1 seq_len:256 free_mem:34.16 GiB
INFO 06-19 08:21:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:41 habana_model_runner.py:955] [Warmup][Decode][575/576] batch_size:2 seq_len:128 free_mem:34.16 GiB
INFO 06-19 08:21:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([2, 1])
INFO 06-19 08:21:41 habana_model_runner.py:955] [Warmup][Decode][576/576] batch_size:1 seq_len:128 free_mem:34.16 GiB
INFO 06-19 08:21:41 habana_model_runner.py:868] not use graph: decode, input shape torch.Size([1, 1])
INFO 06-19 08:21:41 habana_model_runner.py:966] Skipping prompt graph warmup...
INFO 06-19 08:21:41 habana_model_runner.py:955] [Warmup][Graph/Decode][1/576] batch_size:256 seq_len:128 free_mem:34.16 GiB
INFO 06-19 08:21:42 habana_model_runner.py:955] [Warmup][Graph/Decode][2/576] batch_size:256 seq_len:256 free_mem:33.58 GiB
INFO 06-19 08:21:42 habana_model_runner.py:955] [Warmup][Graph/Decode][3/576] batch_size:256 seq_len:384 free_mem:33 GiB
INFO 06-19 08:21:42 habana_model_runner.py:955] [Warmup][Graph/Decode][4/576] batch_size:256 seq_len:512 free_mem:32.42 GiB
INFO 06-19 08:21:43 habana_model_runner.py:955] [Warmup][Graph/Decode][5/576] batch_size:256 seq_len:640 free_mem:31.84 GiB
INFO 06-19 08:21:43 habana_model_runner.py:955] [Warmup][Graph/Decode][6/576] batch_size:256 seq_len:768 free_mem:31.26 GiB
INFO 06-19 08:21:44 habana_model_runner.py:955] [Warmup][Graph/Decode][7/576] batch_size:256 seq_len:896 free_mem:30.68 GiB
INFO 06-19 08:21:44 habana_model_runner.py:955] [Warmup][Graph/Decode][8/576] batch_size:256 seq_len:1024 free_mem:30.1 GiB
INFO 06-19 08:21:45 habana_model_runner.py:955] [Warmup][Graph/Decode][9/576] batch_size:256 seq_len:1152 free_mem:29.52 GiB
INFO 06-19 08:21:45 habana_model_runner.py:955] [Warmup][Graph/Decode][10/576] batch_size:256 seq_len:1280 free_mem:28.94 GiB
INFO 06-19 08:21:46 habana_model_runner.py:955] [Warmup][Graph/Decode][11/576] batch_size:256 seq_len:1408 free_mem:28.36 GiB
INFO 06-19 08:21:46 habana_model_runner.py:955] [Warmup][Graph/Decode][12/576] batch_size:256 seq_len:1536 free_mem:27.77 GiB
INFO 06-19 08:21:47 habana_model_runner.py:955] [Warmup][Graph/Decode][13/576] batch_size:256 seq_len:1664 free_mem:27.19 GiB
INFO 06-19 08:21:47 habana_model_runner.py:955] [Warmup][Graph/Decode][14/576] batch_size:256 seq_len:1792 free_mem:26.6 GiB
INFO 06-19 08:21:48 habana_model_runner.py:955] [Warmup][Graph/Decode][15/576] batch_size:256 seq_len:1920 free_mem:26.02 GiB
INFO 06-19 08:21:49 habana_model_runner.py:955] [Warmup][Graph/Decode][16/576] batch_size:256 seq_len:2048 free_mem:25.43 GiB
INFO 06-19 08:21:49 habana_model_runner.py:955] [Warmup][Graph/Decode][17/576] batch_size:256 seq_len:2176 free_mem:24.84 GiB
INFO 06-19 08:21:50 habana_model_runner.py:955] [Warmup][Graph/Decode][18/576] batch_size:256 seq_len:2304 free_mem:24.26 GiB
INFO 06-19 08:21:51 habana_model_runner.py:955] [Warmup][Graph/Decode][19/576] batch_size:256 seq_len:2432 free_mem:23.67 GiB
INFO 06-19 08:21:51 habana_model_runner.py:955] [Warmup][Graph/Decode][20/576] batch_size:256 seq_len:2560 free_mem:23.08 GiB
INFO 06-19 08:21:52 habana_model_runner.py:955] [Warmup][Graph/Decode][21/576] batch_size:256 seq_len:2688 free_mem:22.5 GiB
INFO 06-19 08:21:53 habana_model_runner.py:955] [Warmup][Graph/Decode][22/576] batch_size:256 seq_len:2816 free_mem:21.91 GiB
INFO 06-19 08:21:54 habana_model_runner.py:955] [Warmup][Graph/Decode][23/576] batch_size:256 seq_len:2944 free_mem:21.32 GiB
INFO 06-19 08:21:55 habana_model_runner.py:955] [Warmup][Graph/Decode][24/576] batch_size:256 seq_len:3072 free_mem:20.73 GiB
INFO 06-19 08:21:55 habana_model_runner.py:955] [Warmup][Graph/Decode][25/576] batch_size:256 seq_len:3200 free_mem:20.14 GiB
INFO 06-19 08:21:56 habana_model_runner.py:955] [Warmup][Graph/Decode][26/576] batch_size:256 seq_len:3328 free_mem:19.55 GiB
INFO 06-19 08:21:57 habana_model_runner.py:955] [Warmup][Graph/Decode][27/576] batch_size:256 seq_len:3456 free_mem:18.96 GiB
INFO 06-19 08:21:58 habana_model_runner.py:955] [Warmup][Graph/Decode][28/576] batch_size:256 seq_len:3584 free_mem:18.37 GiB
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 3712, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 3840, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 3968, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 4096, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 4224, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 4352, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 4480, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 4608, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 4736, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 4864, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 4992, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 5120, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 5248, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 5376, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 5504, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 5632, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 5760, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 5888, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 6016, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 6144, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 6272, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 6400, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 6528, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 6656, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 6784, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 6912, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 7040, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 7168, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 7296, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 7424, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 7552, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 7680, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 7808, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 7936, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 8064, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 256, seq_len: 8192, memory estimated: 628173635.7927405
INFO 06-19 08:21:59 habana_model_runner.py:955] [Warmup][Graph/Decode][65/576] batch_size:128 seq_len:128 free_mem:17.78 GiB
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 256, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 384, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 512, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 640, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 768, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 896, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 1024, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 1152, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 1280, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 1408, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 1536, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 1664, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 1792, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 1920, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 2048, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 2176, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 2304, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 2432, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 2560, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 2688, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 2816, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 2944, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 3072, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 3200, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 3328, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 3456, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 3584, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 3712, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 3840, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 3968, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 4096, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 4224, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 4352, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 4480, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 4608, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 4736, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 4864, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 4992, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 5120, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 5248, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 5376, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 5504, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 5632, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 5760, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 5888, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 6016, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 6144, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 6272, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 6400, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 6528, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 6656, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 6784, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 6912, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 7040, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 7168, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 7296, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 7424, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 7552, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 7680, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 7808, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 7936, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 8064, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 128, seq_len: 8192, memory estimated: 314040308.39579105
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 128, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 256, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 384, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 512, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 640, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 768, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 896, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 1024, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 1152, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 1280, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 1408, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 1536, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 1664, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 1792, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 1920, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 2048, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 2176, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 2304, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 2432, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 2560, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 2688, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 2816, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 2944, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 3072, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 3200, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 3328, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 3456, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 3584, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 3712, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 3840, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 3968, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 4096, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 4224, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 4352, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 4480, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 4608, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 4736, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 4864, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 4992, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 5120, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 5248, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 5376, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 5504, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 5632, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 5760, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 5888, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 6016, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 6144, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 6272, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 6400, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 6528, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 6656, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 6784, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 6912, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 7040, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 7168, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 7296, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 7424, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 7552, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 7680, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 7808, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 7936, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 8064, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 64, seq_len: 8192, memory estimated: 157020154.19789553
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 128, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 256, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 384, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 512, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 640, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 768, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 896, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1024, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1152, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1280, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1408, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1536, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1664, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1792, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 1920, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 2048, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 2176, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 2304, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 2432, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 2560, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 2688, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 2816, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 2944, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 3072, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 3200, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 3328, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 3456, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 3584, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 3712, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 3840, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 3968, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 4096, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 4224, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 4352, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 4480, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 4608, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 4736, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 4864, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 4992, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 5120, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 5248, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 5376, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 5504, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 5632, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 5760, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 5888, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 6016, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 6144, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 6272, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 6400, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 6528, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 6656, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 6784, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 6912, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 7040, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 7168, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 7296, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 7424, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 7552, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 7680, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 7808, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 7936, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 8064, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 32, seq_len: 8192, memory estimated: 78510077.09894776
INFO 06-19 08:21:59 habana_model_runner.py:955] [Warmup][Graph/Decode][257/576] batch_size:16 seq_len:128 free_mem:17.49 GiB
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 256, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 384, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 512, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 640, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 768, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 896, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1024, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1152, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1280, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1408, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1536, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1664, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1792, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 1920, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 2048, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 2176, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 2304, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 2432, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 2560, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 2688, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 2816, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 2944, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 3072, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 3200, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 3328, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 3456, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 3584, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 3712, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 3840, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 3968, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 4096, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 4224, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 4352, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 4480, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 4608, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 4736, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 4864, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 4992, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 5120, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 5248, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 5376, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 5504, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 5632, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 5760, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 5888, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 6016, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 6144, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 6272, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 6400, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 6528, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 6656, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 6784, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 6912, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 7040, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 7168, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 7296, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 7424, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 7552, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 7680, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 7808, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 7936, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 8064, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 16, seq_len: 8192, memory estimated: 39254411.15667243
INFO 06-19 08:22:00 habana_model_runner.py:955] [Warmup][Graph/Decode][321/576] batch_size:8 seq_len:128 free_mem:17.46 GiB
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 256, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 384, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 512, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 640, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 768, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 896, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1024, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1152, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1280, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1408, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1536, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1664, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1792, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 1920, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 2048, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 2176, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 2304, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 2432, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 2560, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 2688, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 2816, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 2944, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 3072, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 3200, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 3328, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 3456, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 3584, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 3712, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 3840, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 3968, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 4096, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 4224, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 4352, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 4480, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 4608, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 4736, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 4864, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 4992, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 5120, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 5248, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 5376, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 5504, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 5632, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 5760, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 5888, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 6016, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 6144, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 6272, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 6400, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 6528, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 6656, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 6784, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 6912, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 7040, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 7168, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 7296, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 7424, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 7552, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 7680, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 7808, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 7936, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 8064, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 8, seq_len: 8192, memory estimated: 19627027.42144434
INFO 06-19 08:22:00 habana_model_runner.py:955] [Warmup][Graph/Decode][385/576] batch_size:4 seq_len:128 free_mem:17.44 GiB
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 256, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 384, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 512, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 640, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 768, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 896, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1024, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1152, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1280, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1408, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1536, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1664, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1792, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 1920, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 2048, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 2176, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 2304, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 2432, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 2560, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 2688, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 2816, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 2944, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 3072, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 3200, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 3328, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 3456, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 3584, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 3712, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 3840, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 3968, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 4096, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 4224, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 4352, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 4480, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 4608, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 4736, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 4864, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 4992, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 5120, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 5248, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 5376, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 5504, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 5632, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 5760, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 5888, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 6016, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 6144, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 6272, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 6400, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 6528, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 6656, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 6784, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 6912, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 7040, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 7168, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 7296, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 7424, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 7552, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 7680, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 7808, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 7936, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 8064, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 4, seq_len: 8192, memory estimated: 9813469.244474433
INFO 06-19 08:22:00 habana_model_runner.py:955] [Warmup][Graph/Decode][449/576] batch_size:2 seq_len:128 free_mem:17.43 GiB
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 256, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 384, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 512, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 640, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 768, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 896, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1024, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1152, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1280, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1408, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1536, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1664, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1792, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 1920, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 2048, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 2176, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 2304, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 2432, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 2560, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 2688, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 2816, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 2944, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 3072, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 3200, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 3328, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 3456, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 3584, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 3712, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 3840, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 3968, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 4096, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 4224, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 4352, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 4480, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 4608, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 4736, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 4864, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 4992, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 5120, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 5248, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 5376, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 5504, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 5632, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 5760, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 5888, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 6016, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 6144, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 6272, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 6400, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 6528, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 6656, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 6784, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 6912, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 7040, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 7168, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 7296, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 7424, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 7552, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 7680, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 7808, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 7936, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 8064, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 2, seq_len: 8192, memory estimated: 4906723.514779755
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 128, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 256, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 384, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 512, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 640, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 768, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 896, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1024, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1152, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1280, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1408, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1536, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1664, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1792, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 1920, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 2048, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 2176, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 2304, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 2432, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 2560, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 2688, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 2816, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 2944, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 3072, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 3200, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 3328, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 3456, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 3584, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 3712, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 3840, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 3968, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 4096, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 4224, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 4352, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 4480, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 4608, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 4736, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 4864, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 4992, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 5120, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 5248, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 5376, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 5504, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 5632, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 5760, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 5888, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 6016, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 6144, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 6272, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 6400, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 6528, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 6656, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 6784, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 6912, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 7040, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 7168, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 7296, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 7424, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 7552, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 7680, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 7808, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 7936, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 8064, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:989] warmup skipped: is_prompt: False, batch_size: 1, seq_len: 8192, memory estimated: 2453361.7573898775
INFO 06-19 08:22:01 habana_model_runner.py:1000] Graph/Decode captured:33 (5.7%) used_mem:16.74 GiB buckets:[(2, 128), (4, 128), (8, 128), (16, 128), (128, 128), (256, 128), (256, 256), (256, 384), (256, 512), (256, 640), (256, 768), (256, 896), (256, 1024), (256, 1152), (256, 1280), (256, 1408), (256, 1536), (256, 1664), (256, 1792), (256, 1920), (256, 2048), (256, 2176), (256, 2304), (256, 2432), (256, 2560), (256, 2688), (256, 2816), (256, 2944), (256, 3072), (256, 3200), (256, 3328), (256, 3456), (256, 3584)]
INFO 06-19 08:22:01 habana_model_runner.py:1028] Warmup finished in 401 secs, allocated 17.15 GiB of device memory
INFO 06-19 08:22:01 habana_executor.py:83] init_cache_engine took 57.73 GiB of device memory (77.2 GiB/94.62 GiB used) and 2.456 GiB of host memory (10.76 GiB/108.1 GiB used)
INFO 06-19 08:22:01 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:22:02 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:22:03 habana_model_runner.py:313] not use graph for prompt...
INFO 06-19 08:22:03 habana_model_runner.py:313] not use graph for prompt...
Throughput: 1.10 requests/s, 18002.18 tokens/s
